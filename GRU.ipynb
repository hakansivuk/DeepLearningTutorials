{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.07]#, 0.1]\n",
    "hid_layer_size_arr = [64]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.85]#, 0.50 ,0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "f = h5.File(\"assign3_data3.h5\", \"r\")\n",
    "\n",
    "# Convert them to np array\n",
    "trainX = np.array(f['trX'])\n",
    "testX = np.array(f['tstX'])\n",
    "trainY = np.array(f['trY'])\n",
    "testY = np.array(f['tstY'])\n",
    "f.close()\n",
    "\n",
    "train_sample = np.random.choice(3000, 2700, replace=False)\n",
    "train_sample = train_sample.reshape((train_sample.shape[0]))\n",
    "validation_sample = np.array(list(set(range(3000)) - set(train_sample.reshape((2700)))))\n",
    "X_train = trainX.reshape((trainX.shape[0], trainX.shape[2], trainX.shape[1]))[train_sample]\n",
    "X_val = trainX.reshape((trainX.shape[0], trainX.shape[2], trainX.shape[1]))[validation_sample]\n",
    "y_train = trainY[train_sample]\n",
    "y_val = trainY[validation_sample]\n",
    "X_test = testX.reshape((testX.shape[0], testX.shape[2], testX.shape[1]))\n",
    "y_test = testY\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape\n",
    "X_train = X_train/4\n",
    "X_val = X_val/4\n",
    "X_test = X_test/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-1 * X))\n",
    "\n",
    "def sigmoid_backward(X):\n",
    "    return np.multiply(X, 1 - X)\n",
    "\n",
    "def softmax(Z):\n",
    "    e = np.exp(Z)\n",
    "    row_sum = np.sum(e, axis=1).reshape((e.shape[0], 1))\n",
    "    return e / row_sum\n",
    "\n",
    "def RELU(X):\n",
    "    return np.multiply(X, X > 0)\n",
    "\n",
    "def RELU_backward(X):\n",
    "    return 1*(X > 0)\n",
    "\n",
    "def tanh(X):\n",
    "    return ( np.exp(2*X) - 1 ) / ( np.exp(2 * X) + 1)\n",
    "\n",
    "def tanh_backward(X):\n",
    "    return 1 - X**2\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert a.shape[0] == b.shape[0]\n",
    "    p = np.random.permutation(a.shape[0])\n",
    "    return a[p], b[p]\n",
    "\n",
    "def initialize_weights(in_size, hid_state_size, hid_layer_size, out_size):\n",
    "    #https://stackoverflow.com/questions/44883861/initial-bias-values-for-a-neural-network\n",
    "    W = {}\n",
    "    U = {}\n",
    "    b = {}\n",
    "    \n",
    "    t_x = (6/(in_size+hid_state_size))**(1/2)\n",
    "    t_h = (3/hid_state_size)**(1/2)\n",
    "    W['z'] = np.random.uniform(low=-1*t_h, high=t_h, size=(hid_state_size, hid_state_size))\n",
    "    U['z'] = np.random.uniform(low=-1*t_x, high=t_x, size=(in_size, hid_state_size))\n",
    "    b['z'] = np.zeros((1, hid_state_size))\n",
    "    #np.zeros((1, hid_state_size))\n",
    "    W['r'] = np.random.uniform(low=-1*t_h, high=t_h, size=(hid_state_size, hid_state_size))\n",
    "    U['r'] = np.random.uniform(low=-1*t_x, high=t_x, size=(in_size, hid_state_size))\n",
    "    b['r'] = np.zeros((1, hid_state_size))\n",
    "    #np.zeros((1, hid_state_size))\n",
    "    W['h'] = np.random.uniform(low=-1*t_h, high=t_h, size=(hid_state_size, hid_state_size))\n",
    "    U['h'] = np.random.uniform(low=-1*t_x, high=t_x, size=(in_size, hid_state_size))\n",
    "    b['h'] = np.zeros((1, hid_state_size))\n",
    "    \n",
    "    t = (6/(hid_state_size + hid_layer_size))**(1/2)\n",
    "    W['1'] = np.random.uniform(low=-1*t, high=t, size=(hid_state_size, hid_layer_size))\n",
    "    b['1'] = np.zeros((1, hid_layer_size))\n",
    "\n",
    "    t = (6/(hid_layer_size + out_size))**(1/2)\n",
    "    W['2'] = np.random.uniform(low=-1*t, high=t, size=(hid_layer_size, out_size))\n",
    "    b['2'] = np.zeros((1, out_size))\n",
    "    \n",
    "    return W, U, b\n",
    "\n",
    "def predict(X_test, y_test, T, h_init, W, U, b): # Counts true if the true word is in the top ten predictions\n",
    "    Z, R, H_, H, hidden, outputs = forward(X_test, h_init, W, U, b, T)\n",
    "    correct = np.argmax(y_test, axis=1)\n",
    "    predictions = np.argmax(outputs, axis=1)\n",
    "    return np.sum(correct == predictions) / y_test.shape[0]\n",
    "\n",
    "def calculate_errors(o, d):\n",
    "    target_predictions = np.multiply(o, d) # Only target class probs\n",
    "    target_predictions = np.sum(target_predictions, axis=1) \n",
    "    return -1 * np.sum(np.log(target_predictions)) # -yi.log(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_forward(h_t_1, x_t, W, U, b):\n",
    "    z_t = sigmoid(x_t.dot(U['z']) + h_t_1.dot(W['z']) + b['z'])\n",
    "    r_t = sigmoid(x_t.dot(U['r']) + h_t_1.dot(W['r']) + b['r'])\n",
    "    h_t_ = tanh(x_t.dot(U['h']) + np.multiply(r_t, h_t_1.dot(W['h'])) + b['h'])\n",
    "    h_t = np.multiply(1-z_t, h_t_1) + np.multiply(z_t, h_t_)\n",
    "    return z_t, r_t, h_t_, h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://image.slidesharecdn.com/dlsl2017d2l2recurrentneuralnetworksi-170125171004/95/recurrent-neural-networks-i-d2l2-deep-learning-for-speech-and-language-upc-2017-31-638.jpg?cb=1485365064'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_backward(delta_h_t, h_t_1, z_t, r_t, h_t_, x_t, W, U, b):\n",
    "    U_grad = {}\n",
    "    W_grad = {}\n",
    "    b_grad = {}\n",
    "    \n",
    "    e = np.multiply(delta_h_t, z_t)\n",
    "    delta_h_t_ = np.multiply(e, tanh_backward(h_t_))\n",
    "    U_grad['h'] = x_t.transpose().dot(delta_h_t_)\n",
    "    W_grad['h'] = h_t_1.transpose().dot(np.multiply(delta_h_t_, r_t))\n",
    "    b_grad['h'] = np.ones((x_t.shape[0], 1)).transpose().dot(delta_h_t_)\n",
    "    \n",
    "    e = np.multiply(delta_h_t_, h_t_1.dot(W['h']))\n",
    "    delta_r_t = np.multiply(e, sigmoid_backward(r_t))\n",
    "    U_grad['r'] = x_t.transpose().dot(delta_r_t)\n",
    "    W_grad['r'] = h_t_1.transpose().dot(delta_r_t)\n",
    "    b_grad['r'] = np.ones((x_t.shape[0], 1)).transpose().dot(delta_r_t)\n",
    "    \n",
    "    e = np.multiply(delta_h_t, h_t_ - h_t_1)\n",
    "    #e = np.multiply(delta_h_t, -1 * h_t_1)\n",
    "    #e = -1 * delta_h_t\n",
    "    delta_z_t = np.multiply(e, sigmoid_backward(z_t))\n",
    "    U_grad['z'] = x_t.transpose().dot(delta_z_t)\n",
    "    W_grad['z'] = h_t_1.transpose().dot(delta_z_t)\n",
    "    b_grad['z'] = np.ones((x_t.shape[0], 1)).transpose().dot(delta_z_t)\n",
    "    \n",
    "    e = delta_z_t.dot(W['z'].transpose())\n",
    "    e += np.multiply(r_t, delta_h_t_).dot(W['h'].transpose())\n",
    "    e += np.multiply(delta_h_t, 1 - z_t)\n",
    "    e += delta_r_t.dot(W['r'].transpose()) \n",
    "    delta_h_t_1 = e\n",
    "    return delta_h_t_1, W_grad, U_grad, b_grad\n",
    "                     \n",
    "def backward(x, y, h_init, H, Z, R, H_, hidden, out, W, U, b, T):\n",
    "    W_grad = {}\n",
    "    U_grad = {}\n",
    "    b_grad = {}\n",
    "    delta_y = out - y\n",
    "    W_grad['2'] = hidden.transpose().dot(delta_y)\n",
    "    b_grad['2'] = np.ones((hidden.shape[0], 1)).transpose().dot(delta_y)\n",
    "    \n",
    "    e = delta_y.dot(W['2'].transpose())\n",
    "    delta_hidden = np.multiply(e, RELU_backward(hidden))\n",
    "    W_grad['1'] = H[:,:,-1].transpose().dot(delta_hidden)\n",
    "    b_grad['1'] = np.ones((H[:,:,-1].shape[0], 1)).transpose().dot(delta_hidden)\n",
    "    \n",
    "    cur_delta_h = delta_hidden.dot(W['1'].transpose())\n",
    "    \n",
    "    W_grad['h'] = 0\n",
    "    W_grad['r'] = 0\n",
    "    W_grad['z'] = 0\n",
    "    U_grad['h'] = 0\n",
    "    U_grad['r'] = 0\n",
    "    U_grad['z'] = 0\n",
    "    b_grad['h'] = 0\n",
    "    b_grad['r'] = 0\n",
    "    b_grad['z'] = 0\n",
    "    \n",
    "    for t in range(T-1, 0, -1):\n",
    "        cur_delta_h, cur_W_grad, cur_U_grad, cur_b_grad = cell_backward(cur_delta_h, H[:,:,t-1], Z[:,:,t], R[:,:,t], H_[:,:,t], x[:,:,t], W, U, b)\n",
    "        W_grad['h'] += cur_W_grad['h']\n",
    "        W_grad['r'] += cur_W_grad['r']\n",
    "        W_grad['z'] += cur_W_grad['z']\n",
    "        U_grad['h'] += cur_U_grad['h']\n",
    "        U_grad['r'] += cur_U_grad['r']\n",
    "        U_grad['z'] += cur_U_grad['z']\n",
    "        b_grad['h'] += cur_b_grad['h']\n",
    "        b_grad['r'] += cur_b_grad['r']\n",
    "        b_grad['z'] += cur_b_grad['z']\n",
    "    \n",
    "    h_grad, cur_W_grad, cur_U_grad, cur_b_grad = cell_backward(cur_delta_h, np.ones((x.shape[0], 1)).dot(h_init), Z[:,:,0], R[:,:,0], H_[:,:,0], x[:,:,0], W, U, b)\n",
    "    W_grad['h'] += cur_W_grad['h']\n",
    "    W_grad['r'] += cur_W_grad['r']\n",
    "    W_grad['z'] += cur_W_grad['z']\n",
    "    U_grad['h'] += cur_U_grad['h']\n",
    "    U_grad['r'] += cur_U_grad['r']\n",
    "    U_grad['z'] += cur_U_grad['z']\n",
    "    b_grad['h'] += cur_b_grad['h']\n",
    "    b_grad['r'] += cur_b_grad['r']\n",
    "    b_grad['z'] += cur_b_grad['z']\n",
    "    \n",
    "    h_grad = np.sum(h_grad, axis=0).reshape((1, h_init.shape[1]))\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    for key in W_grad.keys():\n",
    "        W_grad[key] /= n\n",
    "    for key in U_grad.keys():\n",
    "        U_grad[key] /= n\n",
    "    for key in b_grad.keys():\n",
    "        b_grad[key] /= n\n",
    "\n",
    "    h_grad /= n\n",
    "                     \n",
    "    return W_grad, U_grad, b_grad, h_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, h_0, W, U, b, T):\n",
    "    H = np.zeros((x.shape[0], h_0.shape[1], T))\n",
    "    Z = np.zeros((x.shape[0], h_0.shape[1], T))\n",
    "    R = np.zeros((x.shape[0], h_0.shape[1], T))\n",
    "    H_ = np.zeros((x.shape[0], h_0.shape[1], T))\n",
    "    \n",
    "    cur_h = h_0\n",
    "    for t in range(T):\n",
    "        z_t, r_t, h_t_, cur_h = cell_forward(cur_h, x[:, :, t], W, U, b)\n",
    "        H[:,:,t] = cur_h\n",
    "        Z[:,:,t] = z_t\n",
    "        R[:,:,t] = r_t\n",
    "        H_[:,:,t] = h_t_\n",
    "    \n",
    "    hidden = RELU(cur_h.dot(W['1']) + b['1'])\n",
    "    O = softmax(hidden.dot(W['2']) + b['2'])\n",
    "    \n",
    "    return Z, R, H_, H, hidden, O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val):\n",
    "    print(f'Train for epoch:{EPOCH_NUM}, batch size:{BATCH_SIZE}, lr: {LR}')\n",
    "\n",
    "    W, U, b = initialize_weights(3, hid_state_size, hid_layer_size, out_size) # initialize the weights\n",
    "\n",
    "    # CSE records\n",
    "    train_CSE = []\n",
    "    val_CSE = []\n",
    "    val_acc = []\n",
    "    delta_prev = None # For momentum\n",
    "    batch_num = int(np.ceil(X_train.shape[0] / BATCH_SIZE))\n",
    "    h_init = np.zeros((1, hid_state_size))\n",
    "    \n",
    "    patience = 2\n",
    "    \n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        if epoch > 0 and epoch % 1 == 0: # Report metrics\n",
    "            # TODO\n",
    "            train_accuracy = predict(X_train, y_train, T, h_init, W, U, b) # Counts true if the true word is in the top ten predictions\n",
    "            val_accuracy = predict(X_val, y_val, T, h_init, W, U, b)\n",
    "            print('Epoch:', epoch)\n",
    "            print('Train CSE:', train_CSE[-1])\n",
    "            print('Validation CSE:', val_CSE[-1])\n",
    "            print('Train accuracy:', train_accuracy)\n",
    "            print('Validation accuracy:', val_accuracy)\n",
    "        # Shuffle dataset\n",
    "        shuffled_X, shuffled_y = unison_shuffled_copies(X_train, y_train)\n",
    "\n",
    "        totalCSE = 0\n",
    "\n",
    "        beginning = 0\n",
    "\n",
    "        for i in range(batch_num):\n",
    "            if i < batch_num - 1:\n",
    "                X = shuffled_X[beginning: beginning + BATCH_SIZE] \n",
    "                y = shuffled_y[beginning: beginning + BATCH_SIZE]\n",
    "            else:\n",
    "                X = shuffled_X[beginning: ] \n",
    "                y = shuffled_y[beginning: ]\n",
    "            beginning += BATCH_SIZE\n",
    "            \n",
    "            # TODO\n",
    "            ####### Calculate activations and errors ############\n",
    "            Z, R, H_, H, hidden, O = forward(X, h_init, W, U, b, T) # Forward pass\n",
    "            totalCSE += calculate_errors(O, y) # Loss calculation\n",
    "            #####################################################\n",
    "            W_grad, U_grad, b_grad, h_grad = backward(X, y, h_init, H, Z, R, H_, hidden, O, W, U, b, T) # Backpropagation algorithm\n",
    "            ##### Delta calculations for momentum ######\n",
    "            delta_W_h = -1 * LR * W_grad['h']\n",
    "            delta_W_z = -1 * LR * W_grad['z']\n",
    "            delta_W_r = -1 * LR * W_grad['r']\n",
    "            delta_U_h = -1 * LR * U_grad['h']\n",
    "            delta_U_z = -1 * LR * U_grad['z']\n",
    "            delta_U_r = -1 * LR * U_grad['r']\n",
    "            delta_b_h = -1 * LR * b_grad['h']\n",
    "            delta_b_z = -1 * LR * b_grad['z']\n",
    "            delta_b_r = -1 * LR * b_grad['r']\n",
    "            delta_W_1 = -1 * LR * W_grad['1']\n",
    "            delta_b_1 = -1 * LR * b_grad['1']\n",
    "            delta_W_2 = -1 * LR * W_grad['2']\n",
    "            delta_b_2 = -1 * LR * b_grad['2']\n",
    "            delta_h = -1 * LR * h_grad\n",
    "            \n",
    "            if delta_prev != None:\n",
    "                delta_W_h += alpha * delta_prev['W_h']\n",
    "                delta_W_z += alpha * delta_prev['W_z']\n",
    "                delta_W_r += alpha * delta_prev['W_r']\n",
    "                delta_U_h += alpha * delta_prev['U_h']\n",
    "                delta_U_z += alpha * delta_prev['U_z']\n",
    "                delta_U_r += alpha * delta_prev['U_r']\n",
    "                delta_b_h += alpha * delta_prev['b_h']\n",
    "                delta_b_z += alpha * delta_prev['b_z']\n",
    "                delta_b_r += alpha * delta_prev['b_r']\n",
    "                delta_W_1 += alpha * delta_prev['W_1']\n",
    "                delta_W_2 += alpha * delta_prev['W_2']\n",
    "                delta_b_1 += alpha * delta_prev['b_1']\n",
    "                delta_b_2 += alpha * delta_prev['b_2']\n",
    "                delta_h += alpha * delta_prev['h_init']\n",
    "            delta_prev = {'W_h': delta_W_h, 'W_z': delta_W_z, 'W_r': delta_W_r, 'U_h': delta_U_h, 'U_z': delta_U_z, 'U_r': delta_U_r, 'b_h': delta_b_h, 'b_z': delta_b_z, 'b_r': delta_b_r, 'W_1': delta_W_1, 'W_2': delta_W_2, 'b_1': delta_b_1, 'b_2': delta_b_2, 'h_init': delta_h}\n",
    "            ###### Update weights ###############\n",
    "            W['h'] += delta_W_h\n",
    "            W['z'] += delta_W_z\n",
    "            W['r'] += delta_W_r\n",
    "            U['h'] += delta_U_h\n",
    "            U['z'] += delta_U_z\n",
    "            U['r'] += delta_U_r\n",
    "            b['h'] += delta_b_h\n",
    "            b['z'] += delta_b_z\n",
    "            b['r'] += delta_b_r\n",
    "            W['1'] += delta_W_1\n",
    "            W['2'] += delta_W_2\n",
    "            b['1'] += delta_b_1\n",
    "            b['2'] += delta_b_2\n",
    "            h_init += delta_h\n",
    "            #####################################\n",
    "\n",
    "        train_CSE.append(totalCSE / X_train.shape[0])\n",
    "        Z, R, H_, H, hidden, O = forward(X_val, h_init, W, U, b, T) # Forward pass\n",
    "        val_CSE.append(calculate_errors(O, y_val) / X_val.shape[0])\n",
    "        val_acc.append(predict(X_val, y_val, T, h_init, W, U, b))\n",
    "        \"\"\"if len(val_CSE) > 1: # Early stopping if validation loss starts to increase or it is stationary\n",
    "            validation_loss_change = (val_CSE[-1] - val_CSE[-2]) / val_CSE[-2]\n",
    "            if validation_loss_change > -1*0.001:\n",
    "                print('Finished at epoch', epoch)\n",
    "                break\"\"\"\n",
    "\n",
    "    return train_CSE, val_CSE, val_acc, W, U, b, h_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for epoch:50, batch size:32, lr: 0.07\n",
      "Epoch: 1\n",
      "Train CSE: 1.686240512438913\n",
      "Validation CSE: 1.6229469420561702\n",
      "Train accuracy: 0.32\n",
      "Validation accuracy: 0.37333333333333335\n",
      "Epoch: 2\n",
      "Train CSE: 1.5086745616557065\n",
      "Validation CSE: 1.419842476158575\n",
      "Train accuracy: 0.3548148148148148\n",
      "Validation accuracy: 0.39\n",
      "Epoch: 3\n",
      "Train CSE: 1.373836245838677\n",
      "Validation CSE: 1.272731160421746\n",
      "Train accuracy: 0.46814814814814815\n",
      "Validation accuracy: 0.4866666666666667\n",
      "Epoch: 4\n",
      "Train CSE: 1.268378959328589\n",
      "Validation CSE: 1.2213311130074709\n",
      "Train accuracy: 0.5366666666666666\n",
      "Validation accuracy: 0.5266666666666666\n",
      "Epoch: 5\n",
      "Train CSE: 1.1521649209031646\n",
      "Validation CSE: 1.205376273051254\n",
      "Train accuracy: 0.5466666666666666\n",
      "Validation accuracy: 0.5366666666666666\n",
      "Epoch: 6\n",
      "Train CSE: 1.078956421413426\n",
      "Validation CSE: 1.1345607736301127\n",
      "Train accuracy: 0.585925925925926\n",
      "Validation accuracy: 0.5333333333333333\n",
      "Epoch: 7\n",
      "Train CSE: 1.0981879422690792\n",
      "Validation CSE: 1.0348406922983424\n",
      "Train accuracy: 0.5988888888888889\n",
      "Validation accuracy: 0.57\n",
      "Epoch: 8\n",
      "Train CSE: 0.9960130252075475\n",
      "Validation CSE: 1.0898576828740112\n",
      "Train accuracy: 0.6\n",
      "Validation accuracy: 0.54\n",
      "Epoch: 9\n",
      "Train CSE: 0.9533288372915988\n",
      "Validation CSE: 1.0354215207001363\n",
      "Train accuracy: 0.6125925925925926\n",
      "Validation accuracy: 0.57\n",
      "Epoch: 10\n",
      "Train CSE: 0.9102806934623454\n",
      "Validation CSE: 1.0353755206338864\n",
      "Train accuracy: 0.6337037037037037\n",
      "Validation accuracy: 0.58\n",
      "Epoch: 11\n",
      "Train CSE: 0.8989624579880019\n",
      "Validation CSE: 0.89857697138493\n",
      "Train accuracy: 0.6566666666666666\n",
      "Validation accuracy: 0.63\n",
      "Epoch: 12\n",
      "Train CSE: 0.8440930608202051\n",
      "Validation CSE: 0.900555387845792\n",
      "Train accuracy: 0.6681481481481482\n",
      "Validation accuracy: 0.62\n",
      "Epoch: 13\n",
      "Train CSE: 0.8054114763977557\n",
      "Validation CSE: 1.0100696433850955\n",
      "Train accuracy: 0.6366666666666667\n",
      "Validation accuracy: 0.5766666666666667\n",
      "Epoch: 14\n",
      "Train CSE: 0.7802023589874523\n",
      "Validation CSE: 0.9343463487105438\n",
      "Train accuracy: 0.6733333333333333\n",
      "Validation accuracy: 0.64\n",
      "Epoch: 15\n",
      "Train CSE: 0.7560610883300947\n",
      "Validation CSE: 0.8372159971525861\n",
      "Train accuracy: 0.7044444444444444\n",
      "Validation accuracy: 0.64\n",
      "Epoch: 16\n",
      "Train CSE: 0.67886250471154\n",
      "Validation CSE: 0.8027982594272626\n",
      "Train accuracy: 0.7429629629629629\n",
      "Validation accuracy: 0.67\n",
      "Epoch: 17\n",
      "Train CSE: 0.6226380442184043\n",
      "Validation CSE: 0.8300847445257199\n",
      "Train accuracy: 0.7325925925925926\n",
      "Validation accuracy: 0.67\n",
      "Epoch: 18\n",
      "Train CSE: 0.6016619199800255\n",
      "Validation CSE: 0.8112412650939422\n",
      "Train accuracy: 0.77\n",
      "Validation accuracy: 0.6633333333333333\n",
      "Epoch: 19\n",
      "Train CSE: 0.7329998404836009\n",
      "Validation CSE: 0.8932058286378863\n",
      "Train accuracy: 0.6611111111111111\n",
      "Validation accuracy: 0.59\n",
      "Epoch: 20\n",
      "Train CSE: 0.7160625723166617\n",
      "Validation CSE: 0.7011518457189704\n",
      "Train accuracy: 0.74\n",
      "Validation accuracy: 0.68\n",
      "Epoch: 21\n",
      "Train CSE: 0.5547549520783507\n",
      "Validation CSE: 0.7070512455925418\n",
      "Train accuracy: 0.7662962962962963\n",
      "Validation accuracy: 0.7066666666666667\n",
      "Epoch: 22\n",
      "Train CSE: 0.5238323003251558\n",
      "Validation CSE: 0.6241869591348116\n",
      "Train accuracy: 0.7814814814814814\n",
      "Validation accuracy: 0.72\n",
      "Epoch: 23\n",
      "Train CSE: 0.48556606948007136\n",
      "Validation CSE: 0.6249581451940753\n",
      "Train accuracy: 0.7992592592592592\n",
      "Validation accuracy: 0.7333333333333333\n",
      "Epoch: 24\n",
      "Train CSE: 0.45276062323426625\n",
      "Validation CSE: 0.6271901476783729\n",
      "Train accuracy: 0.812962962962963\n",
      "Validation accuracy: 0.74\n",
      "Epoch: 25\n",
      "Train CSE: 0.4565644594576201\n",
      "Validation CSE: 0.6213960378621188\n",
      "Train accuracy: 0.8325925925925926\n",
      "Validation accuracy: 0.7433333333333333\n",
      "Epoch: 26\n",
      "Train CSE: 0.4304578951626248\n",
      "Validation CSE: 0.6780040534146619\n",
      "Train accuracy: 0.8411111111111111\n",
      "Validation accuracy: 0.7533333333333333\n",
      "Epoch: 27\n",
      "Train CSE: 0.40084192178767797\n",
      "Validation CSE: 0.6082064433201106\n",
      "Train accuracy: 0.8414814814814815\n",
      "Validation accuracy: 0.7666666666666667\n",
      "Epoch: 28\n",
      "Train CSE: 0.3659202384286699\n",
      "Validation CSE: 0.5936436039417291\n",
      "Train accuracy: 0.8622222222222222\n",
      "Validation accuracy: 0.7966666666666666\n",
      "Epoch: 29\n",
      "Train CSE: 0.350906240711783\n",
      "Validation CSE: 0.6989511399649682\n",
      "Train accuracy: 0.8477777777777777\n",
      "Validation accuracy: 0.74\n",
      "Epoch: 30\n",
      "Train CSE: 0.3379158033694671\n",
      "Validation CSE: 0.6667121354527221\n",
      "Train accuracy: 0.8507407407407407\n",
      "Validation accuracy: 0.78\n",
      "Epoch: 31\n",
      "Train CSE: 0.3342631546493705\n",
      "Validation CSE: 0.6526060028890619\n",
      "Train accuracy: 0.8755555555555555\n",
      "Validation accuracy: 0.77\n",
      "Epoch: 32\n",
      "Train CSE: 0.31701925184521434\n",
      "Validation CSE: 0.6272323779782295\n",
      "Train accuracy: 0.8981481481481481\n",
      "Validation accuracy: 0.7866666666666666\n",
      "Epoch: 33\n",
      "Train CSE: 0.28582359789905903\n",
      "Validation CSE: 0.6062428735231769\n",
      "Train accuracy: 0.9077777777777778\n",
      "Validation accuracy: 0.8\n",
      "Epoch: 34\n",
      "Train CSE: 0.27237531452993646\n",
      "Validation CSE: 0.673406583398507\n",
      "Train accuracy: 0.9037037037037037\n",
      "Validation accuracy: 0.7733333333333333\n",
      "Epoch: 35\n",
      "Train CSE: 0.25426097344535586\n",
      "Validation CSE: 0.6422177318917406\n",
      "Train accuracy: 0.9237037037037037\n",
      "Validation accuracy: 0.81\n",
      "Epoch: 36\n",
      "Train CSE: 0.26436596909913795\n",
      "Validation CSE: 0.6333305442070273\n",
      "Train accuracy: 0.9322222222222222\n",
      "Validation accuracy: 0.7933333333333333\n",
      "Epoch: 37\n",
      "Train CSE: 0.1995104162453926\n",
      "Validation CSE: 0.7208339469179812\n",
      "Train accuracy: 0.8948148148148148\n",
      "Validation accuracy: 0.79\n",
      "Epoch: 38\n",
      "Train CSE: 0.19947240441997957\n",
      "Validation CSE: 0.9391219645513683\n",
      "Train accuracy: 0.8855555555555555\n",
      "Validation accuracy: 0.7733333333333333\n",
      "Epoch: 39\n",
      "Train CSE: 0.2210822905242599\n",
      "Validation CSE: 0.734189495894599\n",
      "Train accuracy: 0.9503703703703704\n",
      "Validation accuracy: 0.7833333333333333\n",
      "Epoch: 40\n",
      "Train CSE: 0.16156316584359395\n",
      "Validation CSE: 0.751512870634945\n",
      "Train accuracy: 0.9433333333333334\n",
      "Validation accuracy: 0.8166666666666667\n",
      "Epoch: 41\n",
      "Train CSE: 0.24933344306684077\n",
      "Validation CSE: 0.824372692236028\n",
      "Train accuracy: 0.8955555555555555\n",
      "Validation accuracy: 0.77\n",
      "Epoch: 42\n",
      "Train CSE: 0.30002268955954337\n",
      "Validation CSE: 0.635555700841489\n",
      "Train accuracy: 0.9174074074074074\n",
      "Validation accuracy: 0.79\n",
      "Epoch: 43\n",
      "Train CSE: 0.1933186171944892\n",
      "Validation CSE: 0.6369213930297072\n",
      "Train accuracy: 0.9266666666666666\n",
      "Validation accuracy: 0.8\n",
      "Epoch: 44\n",
      "Train CSE: 0.1621175074443802\n",
      "Validation CSE: 1.014961011365408\n",
      "Train accuracy: 0.9003703703703704\n",
      "Validation accuracy: 0.77\n",
      "Epoch: 45\n",
      "Train CSE: 0.21466744396898768\n",
      "Validation CSE: 0.6898106645820674\n",
      "Train accuracy: 0.9492592592592592\n",
      "Validation accuracy: 0.7866666666666666\n",
      "Epoch: 46\n",
      "Train CSE: 0.11881137976710361\n",
      "Validation CSE: 0.7336421263672825\n",
      "Train accuracy: 0.9648148148148148\n",
      "Validation accuracy: 0.8366666666666667\n",
      "Epoch: 47\n",
      "Train CSE: 0.11209112460817763\n",
      "Validation CSE: 0.8560274721812198\n",
      "Train accuracy: 0.9562962962962963\n",
      "Validation accuracy: 0.8033333333333333\n",
      "Epoch: 48\n",
      "Train CSE: 0.089990980916802\n",
      "Validation CSE: 0.7874213209316244\n",
      "Train accuracy: 0.9681481481481482\n",
      "Validation accuracy: 0.8066666666666666\n",
      "Epoch: 49\n",
      "Train CSE: 0.08902950080689305\n",
      "Validation CSE: 0.7871500021760441\n",
      "Train accuracy: 0.9677777777777777\n",
      "Validation accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.07]#, 0.1]\n",
    "hid_layer_size_arr = [64]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.85]#, 0.50 ,0.85]\n",
    "\n",
    "#results_train = {}\n",
    "for LR in LR_arr:\n",
    "    for hid_layer_size in hid_layer_size_arr:\n",
    "        for alpha in alpha_arr:\n",
    "            result = train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val)\n",
    "            #results_train[f'{LR}-{hid_layer_size}-{alpha}'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gru_best.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(result, 'gru_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(funcs, labels, title, xlabel, ylabel):\n",
    "    colors = ['black', 'blue', 'red', 'green']\n",
    "    min_epoch = 50\n",
    "    for func in funcs:\n",
    "        if len(func) < min_epoch:\n",
    "            min_epoch = len(func)\n",
    "    for i, func in enumerate(funcs):\n",
    "        plt.plot(range(min_epoch), func[:min_epoch], color=colors[i], label=labels[i])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(X, y, T, h_init, W, U, b): # Counts true if the true word is in the top ten predictions\n",
    "    Z, R, H_, H, hidden, outputs = forward(X, h_init, W, U, b, T)\n",
    "    correct = np.argmax(y, axis=1)\n",
    "    predictions = np.argmax(outputs, axis=1)\n",
    "    conf_matrix = np.zeros((6,6))\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        conf_matrix[prediction, correct[i]] += 1\n",
    "    #print('Confusion matrix:\\n')\n",
    "    #print(conf_matrix)\n",
    "    return conf_matrix, np.sum(correct == predictions) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph([result[1][:33]], ['Validation error'], 'Validation CSE over Epochs', 'Epoch', 'CSE Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[416.   0.   1.   0.  29.   9.]\n",
      " [  4. 449.   0.   0.   1.   1.]\n",
      " [  0.   0. 421.   0.   0.   0.]\n",
      " [  0.   0.   3. 460.   0.   0.]\n",
      " [ 12.   0.  15.   2. 420.   4.]\n",
      " [ 14.   0.   0.   0.   5. 434.]]\n"
     ]
    }
   ],
   "source": [
    "cm,acc = confusion_matrix(X_train, y_train, 150, result[6], result[3], result[4], result[5])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 69.   6.   0.   0.  31.  12.]\n",
      " [  1.  92.   0.   0.   0.   7.]\n",
      " [  0.   0. 100.   3.   0.   0.]\n",
      " [  0.   0.   0.  85.   3.   0.]\n",
      " [ 25.   0.   0.  12.  51.   5.]\n",
      " [  5.   2.   0.   0.  15.  76.]]\n",
      "0.7883333333333333\n"
     ]
    }
   ],
   "source": [
    "cm,acc = confusion_matrix(X_test, y_test, 150, result[6], result[3], result[4], result[5])\n",
    "print(cm)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for epoch:50, batch size:32, lr: 0.1\n",
      "Epoch: 1\n",
      "Train CSE: 1.6664947396908045\n",
      "Validation CSE: 1.5186891852452986\n",
      "Train accuracy: 0.3322222222222222\n",
      "Validation accuracy: 0.36333333333333334\n",
      "Epoch: 2\n",
      "Train CSE: 1.4540187800341275\n",
      "Validation CSE: 1.362450600512562\n",
      "Train accuracy: 0.3874074074074074\n",
      "Validation accuracy: 0.4\n",
      "Epoch: 3\n",
      "Train CSE: 1.3249429978844256\n",
      "Validation CSE: 1.2745676234673324\n",
      "Train accuracy: 0.48518518518518516\n",
      "Validation accuracy: 0.4633333333333333\n",
      "Epoch: 4\n",
      "Train CSE: 1.6558612297090964\n",
      "Validation CSE: 1.8149323082314375\n",
      "Train accuracy: 0.1711111111111111\n",
      "Validation accuracy: 0.12666666666666668\n",
      "Epoch: 5\n",
      "Train CSE: 1.795034015897521\n",
      "Validation CSE: 1.8028969412826934\n",
      "Train accuracy: 0.1711111111111111\n",
      "Validation accuracy: 0.12666666666666668\n",
      "Epoch: 6\n",
      "Train CSE: 1.7968226510479983\n",
      "Validation CSE: 1.7961654728215157\n",
      "Train accuracy: 0.16296296296296298\n",
      "Validation accuracy: 0.2\n",
      "Epoch: 7\n",
      "Train CSE: 1.7970255099791839\n",
      "Validation CSE: 1.7843186125312427\n",
      "Train accuracy: 0.16296296296296298\n",
      "Validation accuracy: 0.2\n",
      "Epoch: 8\n",
      "Train CSE: 1.798346577582435\n",
      "Validation CSE: 1.7924285964763313\n",
      "Train accuracy: 0.16518518518518518\n",
      "Validation accuracy: 0.18\n",
      "Epoch: 9\n",
      "Train CSE: 1.7948129962320922\n",
      "Validation CSE: 1.7954595887640419\n",
      "Train accuracy: 0.16296296296296298\n",
      "Validation accuracy: 0.2\n",
      "Epoch: 10\n",
      "Train CSE: 1.7964065712267738\n",
      "Validation CSE: 1.803060026680671\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Epoch: 11\n",
      "Train CSE: 1.795874455812167\n",
      "Validation CSE: 1.794720147322298\n",
      "Train accuracy: 0.1662962962962963\n",
      "Validation accuracy: 0.17\n",
      "Epoch: 12\n",
      "Train CSE: 1.797832097782403\n",
      "Validation CSE: 1.8026501478323673\n",
      "Train accuracy: 0.1711111111111111\n",
      "Validation accuracy: 0.12666666666666668\n",
      "Epoch: 13\n",
      "Train CSE: 1.7973366269616973\n",
      "Validation CSE: 1.7911841292526007\n",
      "Train accuracy: 0.16296296296296298\n",
      "Validation accuracy: 0.2\n",
      "Epoch: 14\n",
      "Train CSE: 1.7967335481670368\n",
      "Validation CSE: 1.7952235792269728\n",
      "Train accuracy: 0.16518518518518518\n",
      "Validation accuracy: 0.18\n",
      "Epoch: 15\n",
      "Train CSE: 1.7973830396300658\n",
      "Validation CSE: 1.8059293397084488\n",
      "Train accuracy: 0.1711111111111111\n",
      "Validation accuracy: 0.12666666666666668\n",
      "Epoch: 16\n",
      "Train CSE: 1.7966891943274041\n",
      "Validation CSE: 1.7893780620346857\n",
      "Train accuracy: 0.16518518518518518\n",
      "Validation accuracy: 0.18\n",
      "Epoch: 17\n",
      "Train CSE: 1.7957268877822274\n",
      "Validation CSE: 1.7992777698673823\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fdd32b1eee0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhid_layer_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhid_layer_size_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malpha_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_state_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_layer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;31m#results_train[f'{LR}-{hid_layer_size}-{alpha}'] = a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b61beb3e33b0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Report metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Counts true if the true word is in the top ten predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-164cbe06c7ce>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(X_test, y_test, T, h_init, W, U, b)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Counts true if the true word is in the top ten predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9f4cf405b74b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(x, h_0, W, U, b, T)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcur_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mz_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ed5e49fb3eeb>\u001b[0m in \u001b[0;36mcell_forward\u001b[0;34m(h_t_1, x_t, W, U, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcell_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_t_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mh_t_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t_1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-164cbe06c7ce>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.1]#, 0.1]\n",
    "hid_layer_size_arr = [64]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.85]#, 0.50 ,0.85]\n",
    "\n",
    "#results_train = {}\n",
    "for LR in LR_arr:\n",
    "    for hid_layer_size in hid_layer_size_arr:\n",
    "        for alpha in alpha_arr:\n",
    "            result = train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val)\n",
    "            #results_train[f'{LR}-{hid_layer_size}-{alpha}'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "0.0\n",
      "-4.240263848881398e-20\n"
     ]
    }
   ],
   "source": [
    "def check(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val):\n",
    "    W, U, b = initialize_weights(3, hid_state_size, hid_layer_size, out_size) # initialize the weights\n",
    "    h_init = np.random.uniform(low=-6, high=6, size=(1, hid_state_size))\n",
    "    #c_init = np.random.uniform(low=-6, high=6, size=(1, hid_state_size))\n",
    "    \n",
    "    X = X_train[:32,:,:T]\n",
    "    y = y_train[:32]\n",
    "    epsilon = 0.0000001\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_plus = {}\n",
    "    U_epsilon = {}\n",
    "    U_plus = {}\n",
    "    \n",
    "    for key in W.keys():\n",
    "        #print(key)\n",
    "        W_epsilon[key] = W[key]\n",
    "        W_plus[key] = W[key]\n",
    "    for key in U.keys():\n",
    "        U_epsilon[key] = U[key]\n",
    "        U_plus[key] = U[key]\n",
    "    for key in b.keys():\n",
    "        b_epsilon[key] = b[key]\n",
    "        b_plus[key] = b[key]\n",
    "        \n",
    "    h_epsilon = h_init- epsilon\n",
    "    h_plus = h_init + epsilon\n",
    "    #print(c_epsilon)\n",
    "    #print(c_plus)\n",
    "    #print(c_init)\n",
    "    #print(np.sum(W['1']))\n",
    "    #cur_key = 'z'\n",
    "    #b_epsilon[cur_key] = b_epsilon[cur_key] - epsilon\n",
    "    #b_plus[cur_key]= b_plus[cur_key] + epsilon\n",
    "    #print(epsilon)\n",
    "    #print(np.sum(W_epsilon['1']), np.sum(W_plus['1']), np.sum(W['1']))\n",
    "    Z, R, H_, H, hidden, O = forward(X, h_epsilon, W_epsilon, U_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    Z, R, H_, H, hidden, O = forward(X, h_plus, W_plus, U_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    Z, R, H_, H, hidden, O = forward(X, h_init, W, U, b, T) # Forward pass\n",
    "    W_grad, U_grad, b_grad, h_grad = backward(X, y, h_init, H, Z, R, H_, hidden, O, W, U, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(h_grad)\n",
    "    real = (J_2/32 - J_1/32)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    print(real)\n",
    "    print(expected)\n",
    "\n",
    "check(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size,T, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_NUM = 100\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR = 0.01\n",
    "hid_layer_size = 16 #16, 32, 64, 128, 256]\n",
    "alpha = 0#, 0.50 ,0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "rnn_res = joblib.load('rnn_best.joblib')\n",
    "lstm_res = joblib.load('lstm_best.joblib')\n",
    "gru_res = joblib.load('gru_best.joblib')\n",
    "\n",
    "plot_graph([rnn_res[1]], ['RNN'], 'Validation CSE over Epochs', 'Epoch', 'CSE Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eee443",
   "language": "python",
   "name": "eee443"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

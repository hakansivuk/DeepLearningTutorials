{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results are :\n",
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.0007, 0.001, 0.003] (especially 0)\n",
    "hid_layer_size_arr = [64]#, 256]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.85]#, 0.50 ,0.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "f = h5.File(\"assign3_data3.h5\", \"r\")\n",
    "\n",
    "# Convert them to np array\n",
    "trainX = np.array(f['trX'])\n",
    "testX = np.array(f['tstX'])\n",
    "trainY = np.array(f['trY'])\n",
    "testY = np.array(f['tstY'])\n",
    "f.close()\n",
    "\n",
    "train_sample = np.random.choice(3000, 2700, replace=False)\n",
    "train_sample = train_sample.reshape((train_sample.shape[0]))\n",
    "validation_sample = np.array(list(set(range(3000)) - set(train_sample.reshape((2700)))))\n",
    "X_train = trainX.reshape((trainX.shape[0], trainX.shape[2], trainX.shape[1]))[train_sample]\n",
    "X_val = trainX.reshape((trainX.shape[0], trainX.shape[2], trainX.shape[1]))[validation_sample]\n",
    "y_train = trainY[train_sample]\n",
    "y_val = trainY[validation_sample]\n",
    "X_test = testX.reshape((testX.shape[0], testX.shape[2], testX.shape[1]))\n",
    "y_test = testY\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape\n",
    "X_train = X_train/4\n",
    "X_val = X_val/4\n",
    "X_test = X_test/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_forward(h_t_1, x_t, W_h_h, W_x_h, b_h):\n",
    "    h_t = tanh(h_t_1.dot(W_h_h) + x_t.dot(W_x_h) + b_h)\n",
    "    return h_t\n",
    "\n",
    "def forward(x, h_init, W, b, T):\n",
    "    H = np.zeros((x.shape[0], W['h_h'].shape[1], T))\n",
    "    \n",
    "    cur_h = h_init\n",
    "    for t in range(T):\n",
    "        cur_h = cell_forward(cur_h, x[:, :, t], W['h_h'], W['x_h'], b['h'])\n",
    "        H[:,:,t] = cur_h\n",
    "    \n",
    "    hidden = RELU(cur_h.dot(W['1']) + b['1'])\n",
    "    #print(hidden)\n",
    "    O = softmax(hidden.dot(W['2']) + b['2'])\n",
    "    \n",
    "    return H, hidden, O\n",
    "\n",
    "def cell_backward(delta_h_t, h_t_1, x_t, W_h_h, W_x_h, b_h):\n",
    "    W_h_h_grad = h_t_1.transpose().dot(delta_h_t)\n",
    "    W_x_h_grad = x_t.transpose().dot(delta_h_t)\n",
    "    b_h_grad = np.ones((x_t.shape[0], 1)).transpose().dot(delta_h_t)\n",
    "    \n",
    "    e_h_t_1 = delta_h_t.dot(W_h_h.transpose())\n",
    "    delta_h_t_1 = np.multiply(e_h_t_1, tanh_backprop(h_t_1))\n",
    "    \n",
    "    return delta_h_t_1, W_h_h_grad, W_x_h_grad, b_h_grad\n",
    "\n",
    "def backward(x, y, h_init, H, hidden, O, W, b, T):\n",
    "    W_grad = {}\n",
    "    b_grad = {}\n",
    "    delta_y = O - y\n",
    "    W_grad['2'] = hidden.transpose().dot(delta_y)\n",
    "    b_grad['2'] = np.ones((hidden.shape[0], 1)).transpose().dot(delta_y)\n",
    "    \n",
    "    e = delta_y.dot(W['2'].transpose())\n",
    "    delta_hidden = np.multiply(e, RELU_backward(hidden))\n",
    "    W_grad['1'] = H[:,:,-1].transpose().dot(delta_hidden)\n",
    "    b_grad['1'] = np.ones((H[:,:,-1].shape[0], 1)).transpose().dot(delta_hidden)\n",
    "    \n",
    "    e = delta_hidden.dot(W['1'].transpose())\n",
    "    cur_delta_h = np.multiply(e, tanh_backprop(H[:,:,-1]))\n",
    "    \n",
    "    W_grad['h_h'] = 0\n",
    "    W_grad['x_h'] = 0\n",
    "    b_grad['h'] = 0\n",
    "    \n",
    "    for t in range(T-1, 0, -1):\n",
    "        cur_delta_h, cur_W_h_h_grad, cur_W_x_h_grad, cur_b_h_grad = cell_backward(cur_delta_h, H[:,:,t-1], x[:,:,t], W['h_h'], W['x_h'], b['h'])\n",
    "        W_grad['h_h'] += cur_W_h_h_grad\n",
    "        W_grad['x_h'] += cur_W_x_h_grad\n",
    "        b_grad['h'] += cur_b_h_grad\n",
    "    \n",
    "    _, cur_W_h_h_grad, cur_W_x_h_grad, cur_b_h_grad = cell_backward(cur_delta_h, np.ones((x.shape[0], 1)).dot(h_init), x[:,:,0], W['h_h'], W['x_h'], b['h'])\n",
    "    W_grad['h_h'] += cur_W_h_h_grad\n",
    "    W_grad['x_h'] += cur_W_x_h_grad\n",
    "    b_grad['h'] += cur_b_h_grad\n",
    "    h_grad = np.sum(cur_delta_h.dot(W['h_h'].transpose()),axis=0).reshape((1, h_init.shape[1]))\n",
    "    \n",
    "    n = x.shape[0]\n",
    "    W_grad['1'] /= n\n",
    "    W_grad['2'] /= n\n",
    "    W_grad['h_h'] /= n\n",
    "    W_grad['x_h'] /= n\n",
    "    b_grad['h'] /= n\n",
    "    b_grad['1'] /= n\n",
    "    b_grad['2'] /= n\n",
    "    h_grad /= n\n",
    "    return W_grad, b_grad, h_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    e = np.exp(Z)\n",
    "    row_sum = np.sum(e, axis=1).reshape((e.shape[0], 1))\n",
    "    return e / row_sum\n",
    "\n",
    "def RELU(X):\n",
    "    return np.multiply(X, X > 0)\n",
    "\n",
    "def RELU_backward(X):\n",
    "    return 1*(X > 0)\n",
    "\n",
    "def tanh(X):\n",
    "    return ( np.exp(2*X) - 1 ) / ( np.exp(2 * X) + 1)\n",
    "\n",
    "def tanh_backprop(X):\n",
    "    return 1 - X**2\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert a.shape[0] == b.shape[0]\n",
    "    p = np.random.permutation(a.shape[0])\n",
    "    return a[p], b[p]\n",
    "\n",
    "def initialize_weights(in_size, hid_state_size, hid_layer_size, out_size):\n",
    "    #https://stackoverflow.com/questions/44883861/initial-bias-values-for-a-neural-network\n",
    "    W = {}\n",
    "    b = {}\n",
    "    t = (6/(in_size+hid_state_size))**(1/2)\n",
    "    W['x_h'] = np.random.uniform(low=-1*t, high=t, size=(in_size, hid_state_size))\n",
    "    t = (3/(hid_state_size))**(1/2)\n",
    "    W['h_h'] = np.random.uniform(low=-1*t, high=t, size=(hid_state_size, hid_state_size))\n",
    "    b['h'] = np.zeros((1, hid_state_size))\n",
    "    #b['h'] = np.random.uniform(low=-1*t, high=t, size=(1, hid_state_size))\n",
    "    t = (6/(hid_state_size + hid_layer_size))**(1/2)\n",
    "    W['1'] = np.random.uniform(low=-1*t, high=t, size=(hid_state_size, hid_layer_size))\n",
    "    b['1'] = np.zeros((1, hid_layer_size))\n",
    "    #b['1'] = np.random.uniform(low=-1*t, high=t, size=(1, hid_layer_size))\n",
    "    t = (6/(hid_layer_size + out_size))**(1/2)\n",
    "    W['2'] = np.random.uniform(low=-1*t, high=t, size=(hid_layer_size, out_size))\n",
    "    b['2'] = np.zeros((1, out_size))\n",
    "    #b['2'] = np.random.uniform(low=-1*t, high=t, size=(1, out_size))\n",
    "    return W, b\n",
    "\n",
    "def predict(X_test, y_test, T, h_init, W, b): # Counts true if the true word is in the top ten predictions\n",
    "    _, __, outputs = forward(X_test, h_init, W, b, T)\n",
    "    correct = np.argmax(y_test, axis=1)\n",
    "    predictions = np.argmax(outputs, axis=1)\n",
    "    return np.sum(correct == predictions) / y_test.shape[0]\n",
    "\n",
    "def calculate_errors(o, d):\n",
    "    target_predictions = np.multiply(o, d) # Only target class probs\n",
    "    target_predictions = np.sum(target_predictions, axis=1) \n",
    "    return -1 * np.sum(np.log(target_predictions)) # -yi.log(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val):\n",
    "    print(f'Train for epoch:{EPOCH_NUM}, batch size:{BATCH_SIZE}, lr: {LR}')\n",
    "\n",
    "    W, b = initialize_weights(3, hid_state_size, hid_layer_size, out_size) # initialize the weights\n",
    "\n",
    "    # CSE records\n",
    "    train_CSE = []\n",
    "    val_CSE = []\n",
    "    val_acc = []\n",
    "\n",
    "    delta_prev = None # For momentum\n",
    "    batch_num = int(np.ceil(X_train.shape[0] / BATCH_SIZE))\n",
    "    h_init = np.zeros((1, hid_state_size))\n",
    "    patience = 2\n",
    "    W_1 = None\n",
    "    b_1 = None\n",
    "    h_1 = None\n",
    "    W_2 = None\n",
    "    b_2 = None\n",
    "    h_2 = None\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        if epoch > 0 and epoch % 1 == 0: # Report metrics\n",
    "            # TODO\n",
    "            train_accuracy = predict(X_train, y_train, T, h_init, W, b) # Counts true if the true word is in the top ten predictions\n",
    "            val_accuracy = predict(X_val, y_val, T, h_init, W, b)\n",
    "            print('Epoch:', epoch)\n",
    "            print('Train CSE:', train_CSE[-1])\n",
    "            print('Validation CSE:', val_CSE[-1])\n",
    "            print('Train accuracy:', train_accuracy)\n",
    "            print('Validation accuracy:', val_accuracy)\n",
    "        # Shuffle dataset\n",
    "        shuffled_X, shuffled_y = unison_shuffled_copies(X_train, y_train)\n",
    "\n",
    "        totalCSE = 0\n",
    "\n",
    "        beginning = 0\n",
    "\n",
    "        for i in range(batch_num):\n",
    "            if i < batch_num - 1:\n",
    "                X = shuffled_X[beginning: beginning + BATCH_SIZE] \n",
    "                y = shuffled_y[beginning: beginning + BATCH_SIZE]\n",
    "            else:\n",
    "                X = shuffled_X[beginning: ] \n",
    "                y = shuffled_y[beginning: ]\n",
    "            beginning += BATCH_SIZE\n",
    "            \n",
    "            # TODO\n",
    "            ####### Calculate activations and errors ############\n",
    "            H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "            totalCSE += calculate_errors(O, y) # Loss calculation\n",
    "            #####################################################\n",
    "            W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "            ##### Delta calculations for momentum ######\n",
    "            delta_W_h_h = -1 * LR * W_grad['h_h'] \n",
    "            delta_W_x_h = -1 * LR * W_grad['x_h']\n",
    "            delta_W_1 = -1 * LR * W_grad['1']\n",
    "            delta_W_2 = -1 * LR * W_grad['2']\n",
    "            delta_b_h = -1 * LR * b_grad['h']\n",
    "            delta_b_1 = -1 * LR * b_grad['1']\n",
    "            delta_b_2 = -1 * LR * b_grad['2']\n",
    "            delta_h = -1 * LR * h_grad\n",
    "            if delta_prev != None:\n",
    "                delta_W_h_h += alpha * delta_prev['W_h_h']\n",
    "                delta_W_x_h += alpha * delta_prev['W_x_h']\n",
    "                delta_W_1 += alpha * delta_prev['W_1']\n",
    "                delta_W_2 += alpha * delta_prev['W_2']\n",
    "                delta_b_h += alpha * delta_prev['b_h']\n",
    "                delta_b_1 += alpha * delta_prev['b_1']\n",
    "                delta_b_2 += alpha * delta_prev['b_2']\n",
    "                delta_h += alpha * delta_prev['h_init']\n",
    "                \n",
    "            delta_prev = {'W_h_h': delta_W_h_h, 'W_x_h': delta_W_x_h, 'W_1': delta_W_1, 'W_2': delta_W_2, 'b_h': delta_b_h, 'b_1': delta_b_1, 'b_2': delta_b_2, 'h_init': delta_h}\n",
    "            ###### Update weights ###############\n",
    "            W_2 = W_1\n",
    "            b_2 = b_1\n",
    "            h_2 = h_1\n",
    "            W_1 = W\n",
    "            b_1 = b\n",
    "            h_1 = h_init\n",
    "            W['h_h'] += delta_W_h_h\n",
    "            W['x_h'] += delta_W_x_h\n",
    "            W['1'] += delta_W_1\n",
    "            W['2'] += delta_W_2\n",
    "            b['h'] += delta_b_h\n",
    "            b['2'] += delta_b_2\n",
    "            b['1'] += delta_b_1\n",
    "            h_init += delta_h\n",
    "            #####################################\n",
    "\n",
    "        train_CSE.append(totalCSE / X_train.shape[0])\n",
    "        H, hidden, O = forward(X_val, h_init, W, b, T) # Forward pass\n",
    "        val_CSE.append(calculate_errors(O, y_val) / X_val.shape[0])\n",
    "        val_accuracy = predict(X_val, y_val, T, h_init, W, b)\n",
    "        val_acc.append(val_accuracy)\n",
    "        if len(val_CSE) > 1: # Early stopping if validation loss starts to increase or it is stationary\n",
    "            if val_CSE[-1] > val_CSE[-2]:\n",
    "                if patience == 1:\n",
    "                    print('Finished at epoch', epoch)\n",
    "                    return train_CSE, val_CSE, val_acc, W_2, b_2, h_2\n",
    "                else:\n",
    "                    W_last = W\n",
    "                    patience -= 1\n",
    "            else:\n",
    "                patience = 2\n",
    "\n",
    "    return train_CSE, val_CSE, val_acc, W, b, h_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for epoch:50, batch size:32, lr: 0.0007\n",
      "Epoch: 5\n",
      "Train CSE: 1.3735826137100622\n",
      "Validation CSE: 1.4588204951755253\n",
      "Train accuracy: 0.40703703703703703\n",
      "Validation accuracy: 0.38666666666666666\n",
      "Epoch: 10\n",
      "Train CSE: 1.305738768151935\n",
      "Validation CSE: 1.3031544579042922\n",
      "Train accuracy: 0.48962962962962964\n",
      "Validation accuracy: 0.4666666666666667\n",
      "Epoch: 15\n",
      "Train CSE: 1.6457348437023147\n",
      "Validation CSE: 1.6466453855485574\n",
      "Train accuracy: 0.26407407407407407\n",
      "Validation accuracy: 0.25\n",
      "Epoch: 20\n",
      "Train CSE: 1.504286892456163\n",
      "Validation CSE: 1.4899023843310208\n",
      "Train accuracy: 0.3781481481481481\n",
      "Validation accuracy: 0.34\n",
      "Epoch: 25\n",
      "Train CSE: 1.3893517293721331\n",
      "Validation CSE: 1.6062932434318287\n",
      "Train accuracy: 0.29777777777777775\n",
      "Validation accuracy: 0.2966666666666667\n",
      "Epoch: 30\n",
      "Train CSE: 1.7054323817467338\n",
      "Validation CSE: 1.7086455805936236\n",
      "Train accuracy: 0.29703703703703704\n",
      "Validation accuracy: 0.3233333333333333\n",
      "Epoch: 35\n",
      "Train CSE: 1.3360942299087177\n",
      "Validation CSE: 1.3498908206311546\n",
      "Train accuracy: 0.4811111111111111\n",
      "Validation accuracy: 0.45666666666666667\n",
      "Epoch: 40\n",
      "Train CSE: 1.2965527018212917\n",
      "Validation CSE: 1.403336213491548\n",
      "Train accuracy: 0.47185185185185186\n",
      "Validation accuracy: 0.43333333333333335\n",
      "Epoch: 45\n",
      "Train CSE: 1.3323710797927508\n",
      "Validation CSE: 1.320474873569508\n",
      "Train accuracy: 0.47814814814814816\n",
      "Validation accuracy: 0.45\n",
      "Train for epoch:50, batch size:32, lr: 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-233418868bba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhid_layer_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhid_layer_size_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malpha_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mresults_dummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_NUM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_state_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid_layer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-846a8ec443bb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtotalCSE\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalculate_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#####################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mW_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Backpropagation algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;31m##### Delta calculations for momentum ######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mdelta_W_h_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h_h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0264fe6d714f>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(x, y, h_init, H, hidden, O, W, b, T)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcur_delta_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_W_h_h_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_W_x_h_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_b_h_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_delta_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h_h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mW_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h_h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcur_W_h_h_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mW_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcur_W_x_h_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mb_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcur_b_h_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.0007, 0.001, 0.003]\n",
    "hid_layer_size_arr = [64]#, 256]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.85]#, 0.50 ,0.85]\n",
    "\n",
    "results_dummy = []\n",
    "for LR in LR_arr:\n",
    "    for hid_layer_size in hid_layer_size_arr:\n",
    "        for alpha in alpha_arr:\n",
    "            results_dummy.append(train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45666666666666667"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dummy[0][2][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for epoch:50, batch size:32, lr: 0.001\n",
      "Epoch: 5\n",
      "Train CSE: 1.6081058379652637\n",
      "Validation CSE: 1.609592001547455\n",
      "Train accuracy: 0.38814814814814813\n",
      "Validation accuracy: 0.38666666666666666\n",
      "Finished at epoch 7\n",
      "Epoch: 10\n",
      "Train CSE: 1.442667396204285\n",
      "Validation CSE: 1.4603910603135584\n",
      "Train accuracy: 0.4162962962962963\n",
      "Validation accuracy: 0.38666666666666666\n",
      "Finished at epoch 10\n",
      "Finished at epoch 13\n",
      "Epoch: 15\n",
      "Train CSE: 1.3585142371106995\n",
      "Validation CSE: 1.3937872015929942\n",
      "Train accuracy: 0.4737037037037037\n",
      "Validation accuracy: 0.43333333333333335\n",
      "Finished at epoch 15\n",
      "Finished at epoch 17\n",
      "Epoch: 20\n",
      "Train CSE: 1.7114887286636276\n",
      "Validation CSE: 1.7492631542240098\n",
      "Train accuracy: 0.26222222222222225\n",
      "Validation accuracy: 0.24333333333333335\n",
      "Finished at epoch 21\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.5543221794845201\n",
      "Validation CSE: 1.7417461187047478\n",
      "Train accuracy: 0.2388888888888889\n",
      "Validation accuracy: 0.23\n",
      "Finished at epoch 27\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.4359532261603125\n",
      "Validation CSE: 1.491185976324277\n",
      "Train accuracy: 0.43777777777777777\n",
      "Validation accuracy: 0.41333333333333333\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.3471542513664536\n",
      "Validation CSE: 1.5040029525735803\n",
      "Train accuracy: 0.3088888888888889\n",
      "Validation accuracy: 0.31\n",
      "Finished at epoch 36\n",
      "Finished at epoch 38\n",
      "Epoch: 40\n",
      "Train CSE: 1.3030173576504633\n",
      "Validation CSE: 1.3405014884411925\n",
      "Train accuracy: 0.4888888888888889\n",
      "Validation accuracy: 0.44666666666666666\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 43\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.280150020091255\n",
      "Validation CSE: 1.489775646699851\n",
      "Train accuracy: 0.39481481481481484\n",
      "Validation accuracy: 0.38\n",
      "Finished at epoch 47\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.001\n",
      "Epoch: 5\n",
      "Train CSE: 1.5206763068502447\n",
      "Validation CSE: 1.5264607247560638\n",
      "Train accuracy: 0.4025925925925926\n",
      "Validation accuracy: 0.4066666666666667\n",
      "Finished at epoch 6\n",
      "Finished at epoch 8\n",
      "Epoch: 10\n",
      "Train CSE: 1.3803695464785075\n",
      "Validation CSE: 1.384176235879825\n",
      "Train accuracy: 0.42074074074074075\n",
      "Validation accuracy: 0.4066666666666667\n",
      "Finished at epoch 10\n",
      "Finished at epoch 13\n",
      "Finished at epoch 14\n",
      "Epoch: 15\n",
      "Train CSE: 1.3582061420444707\n",
      "Validation CSE: 1.4698940385979906\n",
      "Train accuracy: 0.38222222222222224\n",
      "Validation accuracy: 0.37\n",
      "Finished at epoch 15\n",
      "Finished at epoch 16\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.7306137100345944\n",
      "Validation CSE: 1.8780726868903275\n",
      "Train accuracy: 0.10555555555555556\n",
      "Validation accuracy: 0.10333333333333333\n",
      "Finished at epoch 23\n",
      "Epoch: 25\n",
      "Train CSE: 1.6570951242304128\n",
      "Validation CSE: 1.5722051932443935\n",
      "Train accuracy: 0.3574074074074074\n",
      "Validation accuracy: 0.3466666666666667\n",
      "Finished at epoch 25\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.5230797956388025\n",
      "Validation CSE: 1.5549621311662203\n",
      "Train accuracy: 0.34925925925925927\n",
      "Validation accuracy: 0.32666666666666666\n",
      "Finished at epoch 31\n",
      "Finished at epoch 32\n",
      "Epoch: 35\n",
      "Train CSE: 1.4270000438273458\n",
      "Validation CSE: 1.4392292091890688\n",
      "Train accuracy: 0.39185185185185184\n",
      "Validation accuracy: 0.3566666666666667\n",
      "Finished at epoch 36\n",
      "Epoch: 40\n",
      "Train CSE: 1.3655084040717358\n",
      "Validation CSE: 1.374250413038734\n",
      "Train accuracy: 0.43851851851851853\n",
      "Validation accuracy: 0.4\n",
      "Finished at epoch 40\n",
      "Epoch: 45\n",
      "Train CSE: 1.3306462796697123\n",
      "Validation CSE: 1.3316426961465135\n",
      "Train accuracy: 0.4622222222222222\n",
      "Validation accuracy: 0.43333333333333335\n",
      "Finished at epoch 45\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.001\n",
      "Finished at epoch 1\n",
      "Epoch: 5\n",
      "Train CSE: 1.4596379988363801\n",
      "Validation CSE: 1.4363876807684954\n",
      "Train accuracy: 0.4103703703703704\n",
      "Validation accuracy: 0.38666666666666666\n",
      "Finished at epoch 6\n",
      "Finished at epoch 7\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.2953231092489286\n",
      "Validation CSE: 1.4149342298330017\n",
      "Train accuracy: 0.39444444444444443\n",
      "Validation accuracy: 0.38\n",
      "Finished at epoch 13\n",
      "Epoch: 15\n",
      "Train CSE: 1.2919035815045146\n",
      "Validation CSE: 1.316543130236933\n",
      "Train accuracy: 0.48185185185185186\n",
      "Validation accuracy: 0.4533333333333333\n",
      "Finished at epoch 16\n",
      "Finished at epoch 18\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.2557332964706698\n",
      "Validation CSE: 1.3238806922801158\n",
      "Train accuracy: 0.5040740740740741\n",
      "Validation accuracy: 0.4533333333333333\n",
      "Finished at epoch 22\n",
      "Epoch: 25\n",
      "Train CSE: 1.2670953468026207\n",
      "Validation CSE: 1.2776762034962024\n",
      "Train accuracy: 0.5159259259259259\n",
      "Validation accuracy: 0.48\n",
      "Finished at epoch 25\n",
      "Finished at epoch 27\n",
      "Epoch: 30\n",
      "Train CSE: 1.2082502200384875\n",
      "Validation CSE: 1.2284707414210394\n",
      "Train accuracy: 0.5233333333333333\n",
      "Validation accuracy: 0.49666666666666665\n",
      "Finished at epoch 31\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.1977683462683302\n",
      "Validation CSE: 1.2641018152484196\n",
      "Train accuracy: 0.5292592592592592\n",
      "Validation accuracy: 0.48333333333333334\n",
      "Finished at epoch 35\n",
      "Finished at epoch 38\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.1644983593671254\n",
      "Validation CSE: 1.2358067801619002\n",
      "Train accuracy: 0.48962962962962964\n",
      "Validation accuracy: 0.48\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Epoch: 45\n",
      "Train CSE: 1.2905537087642933\n",
      "Validation CSE: 1.2872975822377366\n",
      "Train accuracy: 0.4803703703703704\n",
      "Validation accuracy: 0.44333333333333336\n",
      "Finished at epoch 45\n",
      "Finished at epoch 48\n",
      "Train for epoch:50, batch size:32, lr: 0.001\n",
      "Finished at epoch 2\n",
      "Epoch: 5\n",
      "Train CSE: 1.5684663543280173\n",
      "Validation CSE: 1.563582136790436\n",
      "Train accuracy: 0.3844444444444444\n",
      "Validation accuracy: 0.36333333333333334\n",
      "Finished at epoch 6\n",
      "Finished at epoch 7\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.750642847509419\n",
      "Validation CSE: 1.8100379323398301\n",
      "Train accuracy: 0.11185185185185186\n",
      "Validation accuracy: 0.12\n",
      "Finished at epoch 11\n",
      "Epoch: 15\n",
      "Train CSE: 1.4270455349624371\n",
      "Validation CSE: 1.4053537899513466\n",
      "Train accuracy: 0.4462962962962963\n",
      "Validation accuracy: 0.45\n",
      "Finished at epoch 15\n",
      "Finished at epoch 17\n",
      "Epoch: 20\n",
      "Train CSE: 1.3815446816386807\n",
      "Validation CSE: 1.3769988485963995\n",
      "Train accuracy: 0.4540740740740741\n",
      "Validation accuracy: 0.43333333333333335\n",
      "Finished at epoch 20\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.3428383702458302\n",
      "Validation CSE: 1.5357914145332683\n",
      "Train accuracy: 0.31555555555555553\n",
      "Validation accuracy: 0.32\n",
      "Finished at epoch 26\n",
      "Finished at epoch 27\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.3138490391836366\n",
      "Validation CSE: 1.412805284992449\n",
      "Train accuracy: 0.4040740740740741\n",
      "Validation accuracy: 0.37333333333333335\n",
      "Finished at epoch 31\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.2946026214927147\n",
      "Validation CSE: 1.4617830878312459\n",
      "Train accuracy: 0.37444444444444447\n",
      "Validation accuracy: 0.38333333333333336\n",
      "Finished at epoch 36\n",
      "Finished at epoch 38\n",
      "Epoch: 40\n",
      "Train CSE: 1.259616088576084\n",
      "Validation CSE: 1.280101512047004\n",
      "Train accuracy: 0.5033333333333333\n",
      "Validation accuracy: 0.45666666666666667\n",
      "Finished at epoch 40\n",
      "Finished at epoch 42\n",
      "Finished at epoch 43\n",
      "Epoch: 45\n",
      "Train CSE: 1.230048375851011\n",
      "Validation CSE: 1.2570608940138603\n",
      "Train accuracy: 0.5174074074074074\n",
      "Validation accuracy: 0.4533333333333333\n",
      "Finished at epoch 45\n",
      "Finished at epoch 46\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.001\n",
      "Finished at epoch 3\n",
      "Epoch: 5\n",
      "Train CSE: 1.4831946567113226\n",
      "Validation CSE: 1.465301332790886\n",
      "Train accuracy: 0.3933333333333333\n",
      "Validation accuracy: 0.35\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.356369031129153\n",
      "Validation CSE: 1.392189202643623\n",
      "Train accuracy: 0.4066666666666667\n",
      "Validation accuracy: 0.41333333333333333\n",
      "Finished at epoch 13\n",
      "Epoch: 15\n",
      "Train CSE: 1.2976492543538205\n",
      "Validation CSE: 1.3035417328295005\n",
      "Train accuracy: 0.46814814814814815\n",
      "Validation accuracy: 0.4533333333333333\n",
      "Finished at epoch 15\n",
      "Finished at epoch 17\n",
      "Finished at epoch 18\n",
      "Epoch: 20\n",
      "Train CSE: 1.6971693780575765\n",
      "Validation CSE: 2.244087440375584\n",
      "Train accuracy: 0.09444444444444444\n",
      "Validation accuracy: 0.08\n",
      "Finished at epoch 21\n",
      "Finished at epoch 22\n",
      "Finished at epoch 23\n",
      "Epoch: 25\n",
      "Train CSE: 1.5546294351924024\n",
      "Validation CSE: 1.4528263327217428\n",
      "Train accuracy: 0.3977777777777778\n",
      "Validation accuracy: 0.39\n",
      "Finished at epoch 26\n",
      "Finished at epoch 28\n",
      "Epoch: 30\n",
      "Train CSE: 1.3868241935999313\n",
      "Validation CSE: 1.4048595505720582\n",
      "Train accuracy: 0.4374074074074074\n",
      "Validation accuracy: 0.4033333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at epoch 31\n",
      "Epoch: 35\n",
      "Train CSE: 1.324875568651365\n",
      "Validation CSE: 1.321631481684067\n",
      "Train accuracy: 0.46111111111111114\n",
      "Validation accuracy: 0.44666666666666666\n",
      "Finished at epoch 35\n",
      "Finished at epoch 38\n",
      "Epoch: 40\n",
      "Train CSE: 1.2573575283477882\n",
      "Validation CSE: 1.3016804836282494\n",
      "Train accuracy: 0.5022222222222222\n",
      "Validation accuracy: 0.45\n",
      "Finished at epoch 41\n",
      "Epoch: 45\n",
      "Train CSE: 1.2525570216487276\n",
      "Validation CSE: 1.2642135368428478\n",
      "Train accuracy: 0.5037037037037037\n",
      "Validation accuracy: 0.4666666666666667\n",
      "Finished at epoch 45\n",
      "Finished at epoch 46\n",
      "Finished at epoch 48\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.001\n",
      "Finished at epoch 2\n",
      "Finished at epoch 3\n",
      "Epoch: 5\n",
      "Train CSE: 1.7563460478277304\n",
      "Validation CSE: 1.740513747978765\n",
      "Train accuracy: 0.3396296296296296\n",
      "Validation accuracy: 0.30333333333333334\n",
      "Finished at epoch 6\n",
      "Epoch: 10\n",
      "Train CSE: 1.452402328184443\n",
      "Validation CSE: 1.4023563296331027\n",
      "Train accuracy: 0.4140740740740741\n",
      "Validation accuracy: 0.41\n",
      "Finished at epoch 10\n",
      "Finished at epoch 12\n",
      "Epoch: 15\n",
      "Train CSE: 1.3526891622878334\n",
      "Validation CSE: 1.3412602126364122\n",
      "Train accuracy: 0.44555555555555554\n",
      "Validation accuracy: 0.42333333333333334\n",
      "Finished at epoch 16\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.325604474598581\n",
      "Validation CSE: 1.3063440374945667\n",
      "Train accuracy: 0.4633333333333333\n",
      "Validation accuracy: 0.43666666666666665\n",
      "Finished at epoch 21\n",
      "Finished at epoch 22\n",
      "Finished at epoch 23\n",
      "Epoch: 25\n",
      "Train CSE: 1.8045844804050268\n",
      "Validation CSE: 1.7327891827003628\n",
      "Train accuracy: 0.33444444444444443\n",
      "Validation accuracy: 0.3233333333333333\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.6457683393430351\n",
      "Validation CSE: 1.7671829557146432\n",
      "Train accuracy: 0.18592592592592594\n",
      "Validation accuracy: 0.19666666666666666\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Epoch: 35\n",
      "Train CSE: 1.615872609999421\n",
      "Validation CSE: 1.6606157969343538\n",
      "Train accuracy: 0.3396296296296296\n",
      "Validation accuracy: 0.2966666666666667\n",
      "Finished at epoch 36\n",
      "Epoch: 40\n",
      "Train CSE: 1.5994973699221635\n",
      "Validation CSE: 1.59634524738348\n",
      "Train accuracy: 0.4140740740740741\n",
      "Validation accuracy: 0.37333333333333335\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.3528973572673986\n",
      "Validation CSE: 1.4270122051770289\n",
      "Train accuracy: 0.4688888888888889\n",
      "Validation accuracy: 0.45\n",
      "Train for epoch:50, batch size:32, lr: 0.01\n",
      "Finished at epoch 2\n",
      "Finished at epoch 3\n",
      "Epoch: 5\n",
      "Train CSE: 1.8297195153925416\n",
      "Validation CSE: 1.8764774752774838\n",
      "Train accuracy: 0.13925925925925925\n",
      "Validation accuracy: 0.11\n",
      "Finished at epoch 7\n",
      "Epoch: 10\n",
      "Train CSE: 1.5981512417304957\n",
      "Validation CSE: 1.5900480405929838\n",
      "Train accuracy: 0.3574074074074074\n",
      "Validation accuracy: 0.33666666666666667\n",
      "Finished at epoch 14\n",
      "Epoch: 15\n",
      "Train CSE: 1.7942144105862798\n",
      "Validation CSE: 1.8293164536500672\n",
      "Train accuracy: 0.2537037037037037\n",
      "Validation accuracy: 0.20333333333333334\n",
      "Finished at epoch 16\n",
      "Finished at epoch 17\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.7809757688069867\n",
      "Validation CSE: 1.7951452145234983\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.15\n",
      "Epoch: 25\n",
      "Train CSE: 1.639855712484316\n",
      "Validation CSE: 1.610442752360299\n",
      "Train accuracy: 0.31666666666666665\n",
      "Validation accuracy: 0.32666666666666666\n",
      "Finished at epoch 28\n",
      "Epoch: 30\n",
      "Train CSE: 1.3652059160040688\n",
      "Validation CSE: 1.4105471818497046\n",
      "Train accuracy: 0.4274074074074074\n",
      "Validation accuracy: 0.41333333333333333\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Epoch: 35\n",
      "Train CSE: 1.3227477752954584\n",
      "Validation CSE: 1.3655997759926741\n",
      "Train accuracy: 0.45925925925925926\n",
      "Validation accuracy: 0.4266666666666667\n",
      "Finished at epoch 36\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.3264830523338536\n",
      "Validation CSE: 1.5736429326284997\n",
      "Train accuracy: 0.4111111111111111\n",
      "Validation accuracy: 0.37\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Epoch: 45\n",
      "Train CSE: 1.325040230545382\n",
      "Validation CSE: 1.3349833705288068\n",
      "Train accuracy: 0.4792592592592593\n",
      "Validation accuracy: 0.4666666666666667\n",
      "Finished at epoch 45\n",
      "Finished at epoch 46\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.01\n",
      "Finished at epoch 1\n",
      "Epoch: 5\n",
      "Train CSE: 1.7329122940247224\n",
      "Validation CSE: 1.6923403082749064\n",
      "Train accuracy: 0.2518518518518518\n",
      "Validation accuracy: 0.25666666666666665\n",
      "Finished at epoch 5\n",
      "Finished at epoch 6\n",
      "Epoch: 10\n",
      "Train CSE: 1.4608916714088276\n",
      "Validation CSE: 1.4595203734698086\n",
      "Train accuracy: 0.3611111111111111\n",
      "Validation accuracy: 0.37333333333333335\n",
      "Finished at epoch 12\n",
      "Finished at epoch 13\n",
      "Epoch: 15\n",
      "Train CSE: 1.3896899829343299\n",
      "Validation CSE: 1.4189539803860258\n",
      "Train accuracy: 0.4166666666666667\n",
      "Validation accuracy: 0.38666666666666666\n",
      "Finished at epoch 16\n",
      "Finished at epoch 17\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.299663431063444\n",
      "Validation CSE: 1.6186932595495946\n",
      "Train accuracy: 0.37\n",
      "Validation accuracy: 0.37333333333333335\n",
      "Finished at epoch 22\n",
      "Epoch: 25\n",
      "Train CSE: 1.2872671251533594\n",
      "Validation CSE: 1.3401440511267884\n",
      "Train accuracy: 0.48148148148148145\n",
      "Validation accuracy: 0.4666666666666667\n",
      "Finished at epoch 26\n",
      "Finished at epoch 28\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.50456344756337\n",
      "Validation CSE: 1.5026091237478731\n",
      "Train accuracy: 0.30185185185185187\n",
      "Validation accuracy: 0.3333333333333333\n",
      "Finished at epoch 33\n",
      "Epoch: 35\n",
      "Train CSE: 1.3337767735050148\n",
      "Validation CSE: 1.3292217679308351\n",
      "Train accuracy: 0.44074074074074077\n",
      "Validation accuracy: 0.4533333333333333\n",
      "Finished at epoch 35\n",
      "Finished at epoch 36\n",
      "Finished at epoch 38\n",
      "Epoch: 40\n",
      "Train CSE: 1.2950934062582733\n",
      "Validation CSE: 1.3126642592420197\n",
      "Train accuracy: 0.49666666666666665\n",
      "Validation accuracy: 0.48\n",
      "Finished at epoch 40\n",
      "Finished at epoch 42\n",
      "Finished at epoch 43\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.7743801143062026\n",
      "Validation CSE: 1.6244369499107068\n",
      "Train accuracy: 0.2837037037037037\n",
      "Validation accuracy: 0.2833333333333333\n",
      "Train for epoch:50, batch size:32, lr: 0.01\n",
      "Finished at epoch 2\n",
      "Epoch: 5\n",
      "Train CSE: 1.7961479526958866\n",
      "Validation CSE: 1.7952877492489092\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 6\n",
      "Finished at epoch 7\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.788892229613562\n",
      "Validation CSE: 1.7863886555191606\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 13\n",
      "Epoch: 15\n",
      "Train CSE: 1.7229514935599664\n",
      "Validation CSE: 1.668867092797786\n",
      "Train accuracy: 0.29074074074074074\n",
      "Validation accuracy: 0.29\n",
      "Finished at epoch 15\n",
      "Finished at epoch 18\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.7925655415664925\n",
      "Validation CSE: 1.792835798564738\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 20\n",
      "Finished at epoch 21\n",
      "Finished at epoch 22\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.7922476480060108\n",
      "Validation CSE: 1.7930262760081535\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 25\n",
      "Finished at epoch 26\n",
      "Finished at epoch 27\n",
      "Finished at epoch 28\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.792539220522944\n",
      "Validation CSE: 1.7927313817148407\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 30\n",
      "Finished at epoch 31\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.7926196026871353\n",
      "Validation CSE: 1.7929454398211946\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 35\n",
      "Finished at epoch 36\n",
      "Finished at epoch 37\n",
      "Finished at epoch 38\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.7924074447126401\n",
      "Validation CSE: 1.7923792766351816\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Finished at epoch 43\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.7923194090623946\n",
      "Validation CSE: 1.7927431851324571\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 45\n",
      "Finished at epoch 46\n",
      "Finished at epoch 47\n",
      "Finished at epoch 48\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.01\n",
      "Finished at epoch 4\n",
      "Epoch: 5\n",
      "Train CSE: 1.7725450208515823\n",
      "Validation CSE: 1.7654265860951164\n",
      "Train accuracy: 0.27555555555555555\n",
      "Validation accuracy: 0.2833333333333333\n",
      "Finished at epoch 5\n",
      "Finished at epoch 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Train CSE: 1.6885959820131804\n",
      "Validation CSE: 1.6844372235088294\n",
      "Train accuracy: 0.3085185185185185\n",
      "Validation accuracy: 0.2966666666666667\n",
      "Finished at epoch 10\n",
      "Finished at epoch 13\n",
      "Epoch: 15\n",
      "Train CSE: 1.406876675931674\n",
      "Validation CSE: 1.4462365017106162\n",
      "Train accuracy: 0.4285185185185185\n",
      "Validation accuracy: 0.44\n",
      "Finished at epoch 15\n",
      "Finished at epoch 17\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.5172577735819421\n",
      "Validation CSE: 1.444234295390642\n",
      "Train accuracy: 0.3925925925925926\n",
      "Validation accuracy: 0.37666666666666665\n",
      "Finished at epoch 21\n",
      "Epoch: 25\n",
      "Train CSE: 1.3637719441903804\n",
      "Validation CSE: 1.3973343083249503\n",
      "Train accuracy: 0.45740740740740743\n",
      "Validation accuracy: 0.46\n",
      "Finished at epoch 25\n",
      "Finished at epoch 27\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.337621749957585\n",
      "Validation CSE: 1.3620743092843022\n",
      "Train accuracy: 0.48777777777777775\n",
      "Validation accuracy: 0.4766666666666667\n",
      "Finished at epoch 30\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Epoch: 35\n",
      "Train CSE: 1.4019794497379972\n",
      "Validation CSE: 1.433011560273403\n",
      "Train accuracy: 0.4103703703703704\n",
      "Validation accuracy: 0.39\n",
      "Finished at epoch 35\n",
      "Finished at epoch 38\n",
      "Epoch: 40\n",
      "Train CSE: 1.364925811563166\n",
      "Validation CSE: 1.3971890286960773\n",
      "Train accuracy: 0.4414814814814815\n",
      "Validation accuracy: 0.41\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.3484417406289089\n",
      "Validation CSE: 1.3907309582057406\n",
      "Train accuracy: 0.4533333333333333\n",
      "Validation accuracy: 0.4166666666666667\n",
      "Finished at epoch 45\n",
      "Finished at epoch 48\n",
      "Train for epoch:50, batch size:32, lr: 0.01\n",
      "Finished at epoch 1\n",
      "Finished at epoch 2\n",
      "Epoch: 5\n",
      "Train CSE: 1.8046558785182585\n",
      "Validation CSE: 1.7803270110908704\n",
      "Train accuracy: 0.19666666666666666\n",
      "Validation accuracy: 0.21666666666666667\n",
      "Finished at epoch 5\n",
      "Epoch: 10\n",
      "Train CSE: 1.6728021594863816\n",
      "Validation CSE: 1.6475127742924918\n",
      "Train accuracy: 0.30407407407407405\n",
      "Validation accuracy: 0.34\n",
      "Epoch: 15\n",
      "Train CSE: 1.5029284051893255\n",
      "Validation CSE: 1.4974392940145347\n",
      "Train accuracy: 0.31074074074074076\n",
      "Validation accuracy: 0.31\n",
      "Finished at epoch 16\n",
      "Finished at epoch 18\n",
      "Epoch: 20\n",
      "Train CSE: 1.3921153649908307\n",
      "Validation CSE: 1.4112198174496007\n",
      "Train accuracy: 0.39740740740740743\n",
      "Validation accuracy: 0.38333333333333336\n",
      "Finished at epoch 20\n",
      "Finished at epoch 21\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.3708047047780563\n",
      "Validation CSE: 1.4243635928594294\n",
      "Train accuracy: 0.4085185185185185\n",
      "Validation accuracy: 0.37\n",
      "Finished at epoch 27\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.3686334254575843\n",
      "Validation CSE: 1.4813009271798825\n",
      "Train accuracy: 0.4062962962962963\n",
      "Validation accuracy: 0.36333333333333334\n",
      "Finished at epoch 31\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Epoch: 35\n",
      "Train CSE: 1.337943787477505\n",
      "Validation CSE: 1.3889262581456554\n",
      "Train accuracy: 0.4666666666666667\n",
      "Validation accuracy: 0.42333333333333334\n",
      "Finished at epoch 37\n",
      "Finished at epoch 38\n",
      "Epoch: 40\n",
      "Train CSE: 1.358118546929249\n",
      "Validation CSE: 1.3346402387472118\n",
      "Train accuracy: 0.45037037037037037\n",
      "Validation accuracy: 0.43333333333333335\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.3086765216129856\n",
      "Validation CSE: 1.3385537134034953\n",
      "Train accuracy: 0.447037037037037\n",
      "Validation accuracy: 0.39666666666666667\n",
      "Finished at epoch 45\n",
      "Finished at epoch 48\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.01\n",
      "Epoch: 5\n",
      "Train CSE: 1.5986164840394876\n",
      "Validation CSE: 1.4947234535514176\n",
      "Train accuracy: 0.3951851851851852\n",
      "Validation accuracy: 0.38\n",
      "Finished at epoch 8\n",
      "Epoch: 10\n",
      "Train CSE: 1.3885933618695843\n",
      "Validation CSE: 1.3672494961593062\n",
      "Train accuracy: 0.45444444444444443\n",
      "Validation accuracy: 0.42\n",
      "Finished at epoch 14\n",
      "Epoch: 15\n",
      "Train CSE: 1.3029571071963255\n",
      "Validation CSE: 1.3312083298489124\n",
      "Train accuracy: 0.43444444444444447\n",
      "Validation accuracy: 0.4266666666666667\n",
      "Finished at epoch 16\n",
      "Finished at epoch 17\n",
      "Finished at epoch 18\n",
      "Epoch: 20\n",
      "Train CSE: 1.6939165900323194\n",
      "Validation CSE: 1.6474940217943304\n",
      "Train accuracy: 0.30333333333333334\n",
      "Validation accuracy: 0.30333333333333334\n",
      "Finished at epoch 22\n",
      "Epoch: 25\n",
      "Train CSE: 1.4006943620945251\n",
      "Validation CSE: 1.3930882180741666\n",
      "Train accuracy: 0.4633333333333333\n",
      "Validation accuracy: 0.4066666666666667\n",
      "Finished at epoch 25\n",
      "Finished at epoch 27\n",
      "Epoch: 30\n",
      "Train CSE: 1.3936807384614438\n",
      "Validation CSE: 1.3845224824929896\n",
      "Train accuracy: 0.4274074074074074\n",
      "Validation accuracy: 0.38333333333333336\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.3556668097357987\n",
      "Validation CSE: 1.4602335664387356\n",
      "Train accuracy: 0.40703703703703703\n",
      "Validation accuracy: 0.38666666666666666\n",
      "Finished at epoch 38\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.2988774838184725\n",
      "Validation CSE: 1.3056005257114052\n",
      "Train accuracy: 0.4759259259259259\n",
      "Validation accuracy: 0.43\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.3440184560826915\n",
      "Validation CSE: 1.2965470354492103\n",
      "Train accuracy: 0.447037037037037\n",
      "Validation accuracy: 0.41\n",
      "Finished at epoch 46\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.1\n",
      "Finished at epoch 1\n",
      "Finished at epoch 2\n",
      "Finished at epoch 3\n",
      "Epoch: 5\n",
      "Train CSE: 1.7930208127197542\n",
      "Validation CSE: 1.7914136940996468\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 5\n",
      "Finished at epoch 6\n",
      "Finished at epoch 7\n",
      "Finished at epoch 8\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.7929883662360386\n",
      "Validation CSE: 1.7922238954745509\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 10\n",
      "Finished at epoch 11\n",
      "Finished at epoch 12\n",
      "Finished at epoch 13\n",
      "Finished at epoch 14\n",
      "Epoch: 15\n",
      "Train CSE: 1.7926750649252425\n",
      "Validation CSE: 1.7922904759181448\n",
      "Train accuracy: 0.16592592592592592\n",
      "Validation accuracy: 0.17333333333333334\n",
      "Finished at epoch 15\n",
      "Finished at epoch 16\n",
      "Finished at epoch 17\n",
      "Finished at epoch 18\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.7930557721865326\n",
      "Validation CSE: 1.7926829283576895\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 20\n",
      "Finished at epoch 21\n",
      "Finished at epoch 22\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.792840048619027\n",
      "Validation CSE: 1.7922435131852148\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 25\n",
      "Finished at epoch 27\n",
      "Finished at epoch 28\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.7929149343920148\n",
      "Validation CSE: 1.7930327066459926\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 30\n",
      "Finished at epoch 31\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Epoch: 35\n",
      "Train CSE: 1.7928197339927257\n",
      "Validation CSE: 1.791016344584272\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 35\n",
      "Finished at epoch 36\n",
      "Finished at epoch 37\n",
      "Finished at epoch 38\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.7929523420415263\n",
      "Validation CSE: 1.7935047541939033\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Finished at epoch 43\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.7929576963911769\n",
      "Validation CSE: 1.7917210677599467\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 45\n",
      "Finished at epoch 46\n",
      "Finished at epoch 47\n",
      "Finished at epoch 48\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.1\n",
      "Finished at epoch 1\n",
      "Finished at epoch 3\n",
      "Finished at epoch 4\n",
      "Epoch: 5\n",
      "Train CSE: 1.7874468676731916\n",
      "Validation CSE: 1.7882806638617383\n",
      "Train accuracy: 0.1751851851851852\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 5\n",
      "Finished at epoch 7\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.9149999642108837\n",
      "Validation CSE: 1.7974915847555772\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 12\n",
      "Finished at epoch 13\n",
      "Finished at epoch 14\n",
      "Epoch: 15\n",
      "Train CSE: 1.7938279738275476\n",
      "Validation CSE: 1.7928293833813362\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 15\n",
      "Finished at epoch 16\n",
      "Finished at epoch 17\n",
      "Finished at epoch 18\n",
      "Epoch: 20\n",
      "Train CSE: 1.7937402256108574\n",
      "Validation CSE: 1.7917440853034485\n",
      "Train accuracy: 0.16592592592592592\n",
      "Validation accuracy: 0.17333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at epoch 20\n",
      "Finished at epoch 21\n",
      "Finished at epoch 22\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.793937001151329\n",
      "Validation CSE: 1.7928294242580842\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 25\n",
      "Finished at epoch 26\n",
      "Finished at epoch 27\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.7935075278746782\n",
      "Validation CSE: 1.7935790994717407\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 30\n",
      "Finished at epoch 31\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.7942080307186434\n",
      "Validation CSE: 1.7937437523797135\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 35\n",
      "Finished at epoch 36\n",
      "Finished at epoch 37\n",
      "Finished at epoch 38\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.7935836171940298\n",
      "Validation CSE: 1.7922889247627165\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Finished at epoch 43\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.7934705189116569\n",
      "Validation CSE: 1.795048259171133\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 45\n",
      "Finished at epoch 46\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shbilisim/.local/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  del sys.path[0]\n",
      "/Users/shbilisim/.local/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 10\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 15\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 20\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 25\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 30\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 35\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 40\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 45\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Train for epoch:50, batch size:32, lr: 0.1\n",
      "Finished at epoch 1\n",
      "Finished at epoch 2\n",
      "Finished at epoch 3\n",
      "Finished at epoch 4\n",
      "Epoch: 5\n",
      "Train CSE: 1.7929410366087248\n",
      "Validation CSE: 1.7923443405304913\n",
      "Train accuracy: 0.16592592592592592\n",
      "Validation accuracy: 0.17333333333333334\n",
      "Finished at epoch 5\n",
      "Finished at epoch 6\n",
      "Finished at epoch 7\n",
      "Finished at epoch 8\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.7931609384319178\n",
      "Validation CSE: 1.7927702901242066\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 10\n",
      "Finished at epoch 11\n",
      "Finished at epoch 12\n",
      "Finished at epoch 13\n",
      "Finished at epoch 14\n",
      "Epoch: 15\n",
      "Train CSE: 1.792794536199319\n",
      "Validation CSE: 1.7916733810372034\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 15\n",
      "Finished at epoch 16\n",
      "Finished at epoch 17\n",
      "Finished at epoch 18\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.793125063884292\n",
      "Validation CSE: 1.7930866254342723\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 20\n",
      "Finished at epoch 21\n",
      "Finished at epoch 22\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.7930386292665836\n",
      "Validation CSE: 1.7916422327957973\n",
      "Train accuracy: 0.16592592592592592\n",
      "Validation accuracy: 0.17333333333333334\n",
      "Finished at epoch 25\n",
      "Finished at epoch 26\n",
      "Finished at epoch 27\n",
      "Finished at epoch 28\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.7930476625537635\n",
      "Validation CSE: 1.7918642080156186\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 30\n",
      "Finished at epoch 31\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.793153792732197\n",
      "Validation CSE: 1.7925641446359148\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 35\n",
      "Finished at epoch 36\n",
      "Finished at epoch 37\n",
      "Finished at epoch 38\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.7927977483897468\n",
      "Validation CSE: 1.79255220310932\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Finished at epoch 43\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.7927178168171498\n",
      "Validation CSE: 1.792958349423596\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 45\n",
      "Finished at epoch 46\n",
      "Finished at epoch 47\n",
      "Finished at epoch 48\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.1\n",
      "Finished at epoch 1\n",
      "Finished at epoch 2\n",
      "Finished at epoch 3\n",
      "Finished at epoch 4\n",
      "Epoch: 5\n",
      "Train CSE: 1.7933127763960228\n",
      "Validation CSE: 1.7940116432079674\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 5\n",
      "Finished at epoch 6\n",
      "Finished at epoch 9\n",
      "Epoch: 10\n",
      "Train CSE: 1.7937441010755124\n",
      "Validation CSE: 1.7911989323385515\n",
      "Train accuracy: 0.16592592592592592\n",
      "Validation accuracy: 0.17333333333333334\n",
      "Finished at epoch 10\n",
      "Finished at epoch 11\n",
      "Finished at epoch 13\n",
      "Finished at epoch 14\n",
      "Epoch: 15\n",
      "Train CSE: 1.7935950177762985\n",
      "Validation CSE: 1.793406146878693\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 16\n",
      "Finished at epoch 17\n",
      "Finished at epoch 18\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.793693888213113\n",
      "Validation CSE: 1.7957500963902953\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 20\n",
      "Finished at epoch 22\n",
      "Finished at epoch 23\n",
      "Finished at epoch 24\n",
      "Epoch: 25\n",
      "Train CSE: 1.792829508286211\n",
      "Validation CSE: 1.796542325766361\n",
      "Train accuracy: 0.1685185185185185\n",
      "Validation accuracy: 0.15\n",
      "Finished at epoch 26\n",
      "Finished at epoch 27\n",
      "Finished at epoch 29\n",
      "Epoch: 30\n",
      "Train CSE: 1.7937552330411435\n",
      "Validation CSE: 1.7915165219373594\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Finished at epoch 30\n",
      "Finished at epoch 31\n",
      "Finished at epoch 32\n",
      "Finished at epoch 33\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.7932585125143463\n",
      "Validation CSE: 1.7949654468909304\n",
      "Train accuracy: 0.16703703703703704\n",
      "Validation accuracy: 0.16333333333333333\n",
      "Finished at epoch 35\n",
      "Finished at epoch 36\n",
      "Finished at epoch 37\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.7933424682550527\n",
      "Validation CSE: 1.7937654160417045\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 40\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.792750839340094\n",
      "Validation CSE: 1.7965117789328815\n",
      "Train accuracy: 0.1688888888888889\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Finished at epoch 46\n",
      "Finished at epoch 48\n",
      "Finished at epoch 49\n",
      "Train for epoch:50, batch size:32, lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shbilisim/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "/Users/shbilisim/.local/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 10\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 15\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 20\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 25\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 30\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 35\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 40\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n",
      "Epoch: 45\n",
      "Train CSE: nan\n",
      "Validation CSE: nan\n",
      "Train accuracy: 0.1648148148148148\n",
      "Validation accuracy: 0.18333333333333332\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.001, 0.01, 0.1]\n",
    "hid_layer_size_arr = [64, 256]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.1, 0.50 ,0.85]\n",
    "\n",
    "results_train = {}\n",
    "results_val = {}\n",
    "results_W = {}\n",
    "results_b = {}\n",
    "results_h = {}\n",
    "for LR in LR_arr:\n",
    "    for hid_layer_size in hid_layer_size_arr:\n",
    "        for alpha in alpha_arr:\n",
    "            a, b, c, d, e = train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val)\n",
    "            results_train[f'{LR}-{hid_layer_size}-{alpha}'] = a\n",
    "            results_val[f'{LR}-{hid_layer_size}-{alpha}'] = b\n",
    "            results_W[f'{LR}-{hid_layer_size}-{alpha}'] = c\n",
    "            results_b[f'{LR}-{hid_layer_size}-{alpha}'] = d\n",
    "            results_h[f'{LR}-{hid_layer_size}-{alpha}'] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001-64-0.1\n",
      "1.9940852492437633\n",
      "\n",
      "\n",
      "\n",
      "0.001-64-0.5\n",
      "1.8780726868903275\n",
      "\n",
      "\n",
      "\n",
      "0.001-64-0.85\n",
      "1.7145440360053714\n",
      "\n",
      "\n",
      "\n",
      "0.001-256-0.1\n",
      "1.8100379323398301\n",
      "\n",
      "\n",
      "\n",
      "0.001-256-0.5\n",
      "2.32945054184524\n",
      "\n",
      "\n",
      "\n",
      "0.001-256-0.85\n",
      "1.7697300723674827\n",
      "\n",
      "\n",
      "\n",
      "0.01-64-0.1\n",
      "2.420246716089482\n",
      "\n",
      "\n",
      "\n",
      "0.01-64-0.5\n",
      "1.8724131829825126\n",
      "\n",
      "\n",
      "\n",
      "0.01-64-0.85\n",
      "2.0117914293152457\n",
      "\n",
      "\n",
      "\n",
      "0.01-256-0.1\n",
      "1.8370247455558137\n",
      "\n",
      "\n",
      "\n",
      "0.01-256-0.5\n",
      "1.8292399644855877\n",
      "\n",
      "\n",
      "\n",
      "0.01-256-0.85\n",
      "2.0471627635086587\n",
      "\n",
      "\n",
      "\n",
      "0.1-64-0.1\n",
      "1.7943691973535358\n",
      "\n",
      "\n",
      "\n",
      "0.1-64-0.5\n",
      "1.797660165692455\n",
      "\n",
      "\n",
      "\n",
      "0.1-64-0.85\n",
      "nan\n",
      "\n",
      "\n",
      "\n",
      "0.1-256-0.1\n",
      "1.7939883285330431\n",
      "\n",
      "\n",
      "\n",
      "0.1-256-0.5\n",
      "1.796542325766361\n",
      "\n",
      "\n",
      "\n",
      "0.1-256-0.85\n",
      "nan\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in results_val.keys():\n",
    "    print(key)\n",
    "    print(max(results_val[key]))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for epoch:50, batch size:32, lr: 0.0007\n",
      "Epoch: 1\n",
      "Train CSE: 1.7568993256148897\n",
      "Validation CSE: 1.7143201959817649\n",
      "Train accuracy: 0.25703703703703706\n",
      "Validation accuracy: 0.30666666666666664\n",
      "Epoch: 2\n",
      "Train CSE: 1.6236317789367483\n",
      "Validation CSE: 1.5275835439326093\n",
      "Train accuracy: 0.39185185185185184\n",
      "Validation accuracy: 0.4533333333333333\n",
      "Epoch: 3\n",
      "Train CSE: 1.5073413936284807\n",
      "Validation CSE: 1.4126988157479545\n",
      "Train accuracy: 0.3837037037037037\n",
      "Validation accuracy: 0.44666666666666666\n",
      "Epoch: 4\n",
      "Train CSE: 1.8579448520189328\n",
      "Validation CSE: 1.899897661289443\n",
      "Train accuracy: 0.17444444444444446\n",
      "Validation accuracy: 0.10333333333333333\n",
      "Epoch: 5\n",
      "Train CSE: 1.8050076560805852\n",
      "Validation CSE: 1.8165070418176053\n",
      "Train accuracy: 0.13444444444444445\n",
      "Validation accuracy: 0.10666666666666667\n",
      "Epoch: 6\n",
      "Train CSE: 1.7949555298721844\n",
      "Validation CSE: 1.7730066417878758\n",
      "Train accuracy: 0.18222222222222223\n",
      "Validation accuracy: 0.14666666666666667\n",
      "Epoch: 7\n",
      "Train CSE: 1.7790319835357546\n",
      "Validation CSE: 1.7323610848604745\n",
      "Train accuracy: 0.2903703703703704\n",
      "Validation accuracy: 0.28\n",
      "Epoch: 8\n",
      "Train CSE: 1.7809308313651309\n",
      "Validation CSE: 1.8276624292335142\n",
      "Train accuracy: 0.15481481481481482\n",
      "Validation accuracy: 0.14\n",
      "Epoch: 9\n",
      "Train CSE: 1.7700055438849345\n",
      "Validation CSE: 1.7850515143132055\n",
      "Train accuracy: 0.25592592592592595\n",
      "Validation accuracy: 0.25\n",
      "Epoch: 10\n",
      "Train CSE: 1.75733601857768\n",
      "Validation CSE: 1.7511851158766407\n",
      "Train accuracy: 0.2885185185185185\n",
      "Validation accuracy: 0.3433333333333333\n",
      "Epoch: 11\n",
      "Train CSE: 1.7648283233269575\n",
      "Validation CSE: 1.7159569304400362\n",
      "Train accuracy: 0.25555555555555554\n",
      "Validation accuracy: 0.2866666666666667\n",
      "Epoch: 12\n",
      "Train CSE: 1.7586817404561255\n",
      "Validation CSE: 1.7150510495771956\n",
      "Train accuracy: 0.2514814814814815\n",
      "Validation accuracy: 0.2966666666666667\n",
      "Epoch: 13\n",
      "Train CSE: 1.7528413052446352\n",
      "Validation CSE: 1.7612529565722177\n",
      "Train accuracy: 0.22555555555555556\n",
      "Validation accuracy: 0.2\n",
      "Epoch: 14\n",
      "Train CSE: 1.7554442121713463\n",
      "Validation CSE: 1.744342135664706\n",
      "Train accuracy: 0.30777777777777776\n",
      "Validation accuracy: 0.31\n",
      "Epoch: 15\n",
      "Train CSE: 1.746366298308064\n",
      "Validation CSE: 1.7096544157035907\n",
      "Train accuracy: 0.2959259259259259\n",
      "Validation accuracy: 0.31333333333333335\n",
      "Epoch: 16\n",
      "Train CSE: 1.7247363406551843\n",
      "Validation CSE: 1.704313532048405\n",
      "Train accuracy: 0.2914814814814815\n",
      "Validation accuracy: 0.29\n",
      "Epoch: 17\n",
      "Train CSE: 1.708208416126525\n",
      "Validation CSE: 1.7619309171890511\n",
      "Train accuracy: 0.2644444444444444\n",
      "Validation accuracy: 0.2633333333333333\n",
      "Epoch: 18\n",
      "Train CSE: 1.6628901024042897\n",
      "Validation CSE: 1.6660294556453168\n",
      "Train accuracy: 0.2707407407407407\n",
      "Validation accuracy: 0.27\n",
      "Epoch: 19\n",
      "Train CSE: 1.6370621231023654\n",
      "Validation CSE: 1.7328838455281963\n",
      "Train accuracy: 0.21037037037037037\n",
      "Validation accuracy: 0.22333333333333333\n",
      "Epoch: 20\n",
      "Train CSE: 1.6346613134242052\n",
      "Validation CSE: 1.5402366311793423\n",
      "Train accuracy: 0.3414814814814815\n",
      "Validation accuracy: 0.36666666666666664\n",
      "Epoch: 21\n",
      "Train CSE: 1.5275412464010878\n",
      "Validation CSE: 1.4445078011052053\n",
      "Train accuracy: 0.3648148148148148\n",
      "Validation accuracy: 0.39\n",
      "Epoch: 22\n",
      "Train CSE: 1.5010994991433588\n",
      "Validation CSE: 1.3851711976529293\n",
      "Train accuracy: 0.4462962962962963\n",
      "Validation accuracy: 0.4766666666666667\n",
      "Epoch: 23\n",
      "Train CSE: 1.4232063248039188\n",
      "Validation CSE: 1.3270561583189024\n",
      "Train accuracy: 0.4562962962962963\n",
      "Validation accuracy: 0.49666666666666665\n",
      "Epoch: 24\n",
      "Train CSE: 1.399297558208503\n",
      "Validation CSE: 1.3202952162461645\n",
      "Train accuracy: 0.4588888888888889\n",
      "Validation accuracy: 0.5\n",
      "Epoch: 25\n",
      "Train CSE: 1.346507455012327\n",
      "Validation CSE: 1.4038876118286283\n",
      "Train accuracy: 0.4185185185185185\n",
      "Validation accuracy: 0.44\n",
      "Epoch: 26\n",
      "Train CSE: 1.3788326086672018\n",
      "Validation CSE: 1.312813729257789\n",
      "Train accuracy: 0.4562962962962963\n",
      "Validation accuracy: 0.47\n",
      "Epoch: 27\n",
      "Train CSE: 1.355611865969463\n",
      "Validation CSE: 1.2860405045955106\n",
      "Train accuracy: 0.45666666666666667\n",
      "Validation accuracy: 0.5033333333333333\n",
      "Epoch: 28\n",
      "Train CSE: 1.352865059764359\n",
      "Validation CSE: 1.4791200244715597\n",
      "Train accuracy: 0.3625925925925926\n",
      "Validation accuracy: 0.36333333333333334\n",
      "Epoch: 29\n",
      "Train CSE: 1.327625027290836\n",
      "Validation CSE: 1.2389197259764957\n",
      "Train accuracy: 0.48\n",
      "Validation accuracy: 0.52\n",
      "Epoch: 30\n",
      "Train CSE: 1.3023267648898973\n",
      "Validation CSE: 1.2166063325775225\n",
      "Train accuracy: 0.4866666666666667\n",
      "Validation accuracy: 0.5433333333333333\n",
      "Epoch: 31\n",
      "Train CSE: 1.301293613477159\n",
      "Validation CSE: 1.263874304373205\n",
      "Train accuracy: 0.44666666666666666\n",
      "Validation accuracy: 0.49666666666666665\n",
      "Epoch: 32\n",
      "Train CSE: 1.310037854387055\n",
      "Validation CSE: 1.2168335401514676\n",
      "Train accuracy: 0.4811111111111111\n",
      "Validation accuracy: 0.5233333333333333\n",
      "Epoch: 33\n",
      "Train CSE: 1.2922920665361042\n",
      "Validation CSE: 1.4562509408595585\n",
      "Train accuracy: 0.37037037037037035\n",
      "Validation accuracy: 0.37333333333333335\n",
      "Epoch: 34\n",
      "Train CSE: 1.3375964044246889\n",
      "Validation CSE: 1.2247362833058653\n",
      "Train accuracy: 0.4748148148148148\n",
      "Validation accuracy: 0.54\n",
      "Epoch: 35\n",
      "Train CSE: 1.3598712619777926\n",
      "Validation CSE: 1.4534318704448572\n",
      "Train accuracy: 0.38074074074074077\n",
      "Validation accuracy: 0.38333333333333336\n",
      "Epoch: 36\n",
      "Train CSE: 1.3448707296557347\n",
      "Validation CSE: 1.2569335380929871\n",
      "Train accuracy: 0.46\n",
      "Validation accuracy: 0.51\n",
      "Epoch: 37\n",
      "Train CSE: 1.3105173835925867\n",
      "Validation CSE: 1.2315057025393519\n",
      "Train accuracy: 0.45740740740740743\n",
      "Validation accuracy: 0.5066666666666667\n",
      "Epoch: 38\n",
      "Train CSE: 1.2650226780219263\n",
      "Validation CSE: 1.1759315883212538\n",
      "Train accuracy: 0.4918518518518519\n",
      "Validation accuracy: 0.5266666666666666\n",
      "Epoch: 39\n",
      "Train CSE: 1.284718283635698\n",
      "Validation CSE: 1.1915781516840525\n",
      "Train accuracy: 0.5014814814814815\n",
      "Validation accuracy: 0.5566666666666666\n",
      "Finished at epoch 39\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.0007]#, 0.001, 0.003]\n",
    "hid_layer_size_arr = [64]#, 256]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.85]#, 0.50 ,0.85]\n",
    "\n",
    "results = []\n",
    "for LR in LR_arr:\n",
    "    for hid_layer_size in hid_layer_size_arr:\n",
    "        for alpha in alpha_arr:\n",
    "            results.append(train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load('rnn_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      "[[10.  8.  1. 12.  8.  7.]\n",
      " [ 7. 49.  0. 10.  9. 14.]\n",
      " [ 0.  0. 99.  0.  0.  0.]\n",
      " [66. 20.  0. 45. 44. 53.]\n",
      " [ 5. 11.  0. 22. 20. 12.]\n",
      " [12. 12.  0. 11. 19. 14.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.395"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cm,acc = confusion_matrix(X_test, y_test, 150, loaded[-1], loaded[-3], loaded[-2])\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnn_best.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(results[0], 'rnn_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "0.45666666666666667\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(np.array(results[0][2])))\n",
    "print(np.max(results[1][2]))\n",
    "print(np.argmax(np.array(results[2][2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for epoch:50, batch size:32, lr: 0.01\n",
      "Finished at epoch 4\n",
      "Epoch: 5\n",
      "Train CSE: 1.847436245497743\n",
      "Validation CSE: 1.8228520786700937\n",
      "Train accuracy: 0.27925925925925926\n",
      "Validation accuracy: 0.2833333333333333\n",
      "Finished at epoch 7\n",
      "Epoch: 10\n",
      "Train CSE: 1.631730385608509\n",
      "Validation CSE: 1.6128971368632192\n",
      "Train accuracy: 0.29555555555555557\n",
      "Validation accuracy: 0.28\n",
      "Finished at epoch 12\n",
      "Epoch: 15\n",
      "Train CSE: 1.5179441683113315\n",
      "Validation CSE: 1.521133055278508\n",
      "Train accuracy: 0.2696296296296296\n",
      "Validation accuracy: 0.2733333333333333\n",
      "Finished at epoch 16\n",
      "Finished at epoch 19\n",
      "Epoch: 20\n",
      "Train CSE: 1.5223285433266627\n",
      "Validation CSE: 1.6265814621382262\n",
      "Train accuracy: 0.29777777777777775\n",
      "Validation accuracy: 0.28\n",
      "Finished at epoch 21\n",
      "Finished at epoch 22\n",
      "Epoch: 25\n",
      "Train CSE: 1.5059439962226298\n",
      "Validation CSE: 1.4669163781343497\n",
      "Train accuracy: 0.3425925925925926\n",
      "Validation accuracy: 0.33666666666666667\n",
      "Finished at epoch 25\n",
      "Finished at epoch 26\n",
      "Epoch: 30\n",
      "Train CSE: 1.4792021502612887\n",
      "Validation CSE: 1.4422188901143973\n",
      "Train accuracy: 0.34703703703703703\n",
      "Validation accuracy: 0.36333333333333334\n",
      "Finished at epoch 32\n",
      "Finished at epoch 34\n",
      "Epoch: 35\n",
      "Train CSE: 1.432178104071812\n",
      "Validation CSE: 1.4333815378568906\n",
      "Train accuracy: 0.37703703703703706\n",
      "Validation accuracy: 0.36333333333333334\n",
      "Finished at epoch 35\n",
      "Finished at epoch 37\n",
      "Finished at epoch 39\n",
      "Epoch: 40\n",
      "Train CSE: 1.4272749197281636\n",
      "Validation CSE: 1.4054756222768925\n",
      "Train accuracy: 0.3781481481481481\n",
      "Validation accuracy: 0.41\n",
      "Finished at epoch 41\n",
      "Finished at epoch 42\n",
      "Finished at epoch 44\n",
      "Epoch: 45\n",
      "Train CSE: 1.4228482551121397\n",
      "Validation CSE: 1.4448565633853498\n",
      "Train accuracy: 0.3611111111111111\n",
      "Validation accuracy: 0.36333333333333334\n",
      "Finished at epoch 46\n",
      "Finished at epoch 47\n",
      "Finished at epoch 48\n",
      "Finished at epoch 49\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "hid_state_size = 128\n",
    "out_size = 6\n",
    "T = 150\n",
    "\n",
    "LR_arr = [0.01]\n",
    "hid_layer_size_arr = [32]#, 256]#16, 32, 64, 128, 256]\n",
    "alpha_arr = [0.85]#, 0.50 ,0.85]\n",
    "\n",
    "results_high_lr = []\n",
    "for LR in LR_arr:\n",
    "    for hid_layer_size in hid_layer_size_arr:\n",
    "        for alpha in alpha_arr:\n",
    "            results_high_lr.append(train(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results_high_lr[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.001-256-0'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = 100\n",
    "best_params = None\n",
    "for key in results_val.keys():\n",
    "    cur_max = min(results_val[key])\n",
    "    if cur_max < best:\n",
    "        best = cur_max\n",
    "        best_params = key\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      "[[ 48.  11.   2.   5.  31.  17.]\n",
      " [ 51. 266.  19.  31.  99.  44.]\n",
      " [  7.   4. 394.   0.   9.   0.]\n",
      " [180.  66.   4. 379. 143. 164.]\n",
      " [ 69.  33.  19.  25.  61.  49.]\n",
      " [ 90.  71.   7.  15. 105. 182.]]\n",
      "Confusion matrix:\n",
      "\n",
      "[[  5.   3.   0.  11.   7.   2.]\n",
      " [  3.  34.   0.   1.   4.   2.]\n",
      " [  0.   1. 100.   1.   1.   0.]\n",
      " [ 77.  23.   0.  45.  54.  72.]\n",
      " [  8.  14.   0.   2.  13.   5.]\n",
      " [  7.  25.   0.  40.  21.  19.]]\n"
     ]
    }
   ],
   "source": [
    "best_W = results[2][-3]\n",
    "best_b = results[2][-2]\n",
    "best_h_init = results[2][-1]\n",
    "\n",
    "train_cm, _ = confusion_matrix(X_train, y_train, 150, best_h_init, best_W, best_b)\n",
    "test_cm, test_acc = confusion_matrix(X_test, y_test, 150, best_h_init, best_W, best_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_cm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7143201959817649,\n",
       " 1.5275835439326093,\n",
       " 1.4126988157479545,\n",
       " 1.899897661289443,\n",
       " 1.8165070418176053,\n",
       " 1.7730066417878758,\n",
       " 1.7323610848604745,\n",
       " 1.8276624292335142,\n",
       " 1.7850515143132055,\n",
       " 1.7511851158766407,\n",
       " 1.7159569304400362,\n",
       " 1.7150510495771956,\n",
       " 1.7612529565722177,\n",
       " 1.744342135664706,\n",
       " 1.7096544157035907,\n",
       " 1.704313532048405,\n",
       " 1.7619309171890511,\n",
       " 1.6660294556453168,\n",
       " 1.7328838455281963,\n",
       " 1.5402366311793423,\n",
       " 1.4445078011052053,\n",
       " 1.3851711976529293,\n",
       " 1.3270561583189024,\n",
       " 1.3202952162461645,\n",
       " 1.4038876118286283,\n",
       " 1.312813729257789,\n",
       " 1.2860405045955106,\n",
       " 1.4791200244715597,\n",
       " 1.2389197259764957,\n",
       " 1.2166063325775225,\n",
       " 1.263874304373205,\n",
       " 1.2168335401514676,\n",
       " 1.4562509408595585,\n",
       " 1.2247362833058653,\n",
       " 1.4534318704448572,\n",
       " 1.2569335380929871,\n",
       " 1.2315057025393519,\n",
       " 1.1759315883212538,\n",
       " 1.1915781516840525,\n",
       " 1.3066174281133636]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss = results[0][1]\n",
    "validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(funcs, labels, title, xlabel, ylabel):\n",
    "    colors = ['black', 'blue', 'red', 'green']\n",
    "    min_epoch = 50\n",
    "    for func in funcs:\n",
    "        if len(func) < min_epoch:\n",
    "            min_epoch = len(func)\n",
    "    for i, func in enumerate(funcs):\n",
    "        plt.plot(range(min_epoch), func[:min_epoch], color=colors[i], label=labels[i])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph([validation_loss], ['Validation error'], 'Validation CSE over Epochs', 'Epoch', 'CSE Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(X, y, T, h_init, W, b): # Counts true if the true word is in the top ten predictions\n",
    "    _, __, outputs = forward(X, h_init, W, b, T)\n",
    "    correct = np.argmax(y, axis=1)\n",
    "    predictions = np.argmax(outputs, axis=1)\n",
    "    conf_matrix = np.zeros((6,6))\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        conf_matrix[prediction, correct[i]] += 1\n",
    "    print('Confusion matrix:\\n')\n",
    "    print(conf_matrix)\n",
    "    return conf_matrix, np.sum(correct == predictions) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_W = results[0][3]\n",
    "best_b = results[0][4]\n",
    "best_h = results[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "\n",
      "[[10.  8.  1. 12.  8.  7.]\n",
      " [ 7. 49.  0. 10.  9. 14.]\n",
      " [ 0.  0. 99.  0.  0.  0.]\n",
      " [66. 20.  0. 45. 44. 53.]\n",
      " [ 5. 11.  0. 22. 20. 12.]\n",
      " [12. 12.  0. 11. 19. 14.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.395"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm, acc = confusion_matrix(X_test, y_test, 150, best_h, best_W, best_b)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  8.  1. 12.  8.  7.]\n",
      " [ 7. 49.  0. 10.  9. 14.]\n",
      " [ 0.  0. 99.  0.  0.  0.]\n",
      " [66. 20.  0. 45. 44. 53.]\n",
      " [ 5. 11.  0. 22. 20. 12.]\n",
      " [12. 12.  0. 11. 19. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3880597014925373\n",
      "0.9999999977007771 5.507722389275216e-08 6.331740687315346e-17\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.006\n",
    "hid_state_size = 128\n",
    "hid_layer_size = 64\n",
    "out_size = 6\n",
    "alpha = 0.85\n",
    "T = 150\n",
    "check2(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val):\n",
    "    W, b = initialize_weights(3, hid_state_size, hid_layer_size, out_size) # initialize the weights\n",
    "    h_init = np.random.uniform(low=-1, high=1, size=(1, hid_state_size))\n",
    "   \n",
    "    X = X_train[:32]\n",
    "    y = y_train[:32]\n",
    "    epsilon = 0.0000001\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] - epsilon\n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] + epsilon\n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(W_grad['h_h'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']- epsilon\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']+ epsilon\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(W_grad['x_h'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']- epsilon\n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']+ epsilon\n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(W_grad['1'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']- epsilon\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']+ epsilon\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(W_grad['2'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']- epsilon\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']+ epsilon\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(b_grad['h'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']- epsilon\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']+ epsilon\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(b_grad['1'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']- epsilon\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']+ epsilon\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(b_grad['2'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init - epsilon\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init + epsilon\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(h_grad)\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check2(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val):\n",
    "    W, b = initialize_weights(3, hid_state_size, hid_layer_size, out_size) # initialize the weights\n",
    "    h_init = np.random.uniform(low=-1, high=1, size=(1, hid_state_size))\n",
    "   \n",
    "    X = X_train[:32]\n",
    "    y = y_train[:32]\n",
    "    epsilon = 0.0000001\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1']\n",
    "    W_epsilon['2'] = W['2']- epsilon\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1']\n",
    "    W_plus['2'] = W['2']+ epsilon\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(W_grad['2'])\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected))\n",
    "    \n",
    "    W_epsilon = {}\n",
    "    b_epsilon = {}\n",
    "    b_plus = {}\n",
    "    W_epsilon['h_h'] = W['h_h'] \n",
    "    W_epsilon['x_h'] = W['x_h']\n",
    "    W_epsilon['1'] = W['1'] \n",
    "    W_epsilon['2'] = W['2']\n",
    "    b_epsilon['h'] = b['h']\n",
    "    b_epsilon['1'] = b['1']\n",
    "    b_epsilon['2'] = b['2']\n",
    "    h_epsilon = h_init - epsilon\n",
    "    W_plus = {}\n",
    "    W_plus['h_h'] = W['h_h'] \n",
    "    W_plus['x_h'] = W['x_h']\n",
    "    W_plus['1'] = W['1'] \n",
    "    W_plus['2'] = W['2']\n",
    "    b_plus['h'] = b['h']\n",
    "    b_plus['1'] = b['1']\n",
    "    b_plus['2'] = b['2']\n",
    "    h_plus = h_init + epsilon\n",
    "    H, hidden, O = forward(X, h_epsilon, W_epsilon, b_epsilon, T) # Forward pass\n",
    "    J_1 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_plus, W_plus, b_plus, T) # Forward pass\n",
    "    J_2 = calculate_errors(O, y) # Loss calculation\n",
    "    H, hidden, O = forward(X, h_init, W, b, T) # Forward pass\n",
    "    W_grad, b_grad, h_grad = backward(X, y, h_init, H, hidden, O, W, b, T) # Backpropagation algorithm\n",
    "    expected = np.sum(h_grad)\n",
    "    real = (J_2 - J_1)/(2*epsilon)\n",
    "    print((real-expected)/(real+expected), real, expected)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-6.601731803673805e-05 -1.2002621119222567e-05 -1.2004205985562597e-05\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.006\n",
    "hid_state_size = 128\n",
    "hid_layer_size = 64\n",
    "out_size = 6\n",
    "alpha = 0.85\n",
    "T = 150\n",
    "check2(EPOCH_NUM, BATCH_SIZE, LR, alpha, hid_state_size, hid_layer_size, out_size, T, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eee443",
   "language": "python",
   "name": "eee443"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
